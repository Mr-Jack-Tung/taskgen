{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa1e388-b8f4-4fa3-be5a-ba7c6caae038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 6 - External Function Interfacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75f665-03e3-48d9-bc70-fab5f0549424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install taskgen-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "076adf5e-beb1-4b19-9078-34ab1b7d9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up API key and do the necessary imports\n",
    "import os\n",
    "from taskgen import *\n",
    "import random\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b9a5f-7e80-4a03-a822-8135b1f8da3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding Python Function directly to Function\n",
    "- You should write a docstring that describes the function and contains all the input variable names that are not `args`, `kwargs` or `shared_variables`\n",
    "- typing for inputs and outputs will be automatically converted to TaskGen `Function` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed33cbb-bc0e-45ca-b06b-68cdeb50a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\n",
    "    ''' Appends num1 to num_list '''\n",
    "    num_list.append(num1)\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca759a1-49bf-4d96-9494-f387c9526256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = Function(external_fn = add_number_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23d77ff-fd6d-4668-85a1-450278c881aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Appends <num1: int> to <num_list: list[int]> \n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'output_1': 'list[int]'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367956e-916b-441c-906c-892090eee051",
   "metadata": {},
   "source": [
    "# Adding Python Function directly to Agent\n",
    "- We can also assign the Python function directly to an Agent and it will automatically convert it to `Function` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e6c470-92a6-4fe1-8370-a9c74c1cf390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Math Whiz', 'Does Math Calculations').assign_functions([add_number_to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3b6747-64a5-4e9e-858c-cddd5e0de689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add_number_to_list\\nDescription:  Appends <num1: int> to <num_list: list[int]> \\nInput: ['num1', 'num_list']\\nOutput: {'output_1': 'list[int]'}\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5238a9a6-a654-482c-811a-0f4c8d21f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Append the number 5 to the list [2, 4]\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "Subtask identified: Append 5 to [2, 4]\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': [2, 4, 5]}, {'output_1': [2, 4, 5]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Append 5 to [2, 4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6a7b7-2fdb-407e-bd5c-3024c007a8a5",
   "metadata": {},
   "source": [
    "# CrewAI Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8455989c-b934-49ee-aaed-e3562002722a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b93ebcb-022b-482a-8a2c-184e208402e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2c37c1b-439b-4948-ba2b-e1266e394a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# just wrap the external tool within a function\n",
    "def scrape_website_tool(website_url: str) -> str:\n",
    "    ''' Scrapes data from website_url '''\n",
    "    # import the tool\n",
    "    from crewai_tools import ScrapeWebsiteTool\n",
    "    \n",
    "    # initialise the tool\n",
    "    docs_scrape_tool = ScrapeWebsiteTool(\n",
    "        website_url=website_url)\n",
    "    \n",
    "    # run the tool\n",
    "    return docs_scrape_tool.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74d03606-5399-4056-9ed2-d8c7e6a262f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Website summariser', 'Scrapes and then summarises a website to the user').assign_functions([scrape_website_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c23c8d1-0b4e-40d7-9dfd-12c69ac16016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Scrape the website \"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
      "Calling function scrape_website_tool with parameters {'website_url': 'https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/'}\n",
      "Using Tool: Read website content\n",
      "> {'output_1': 'Assembling and Activating Your CrewAI Team - crewAI\\n Skip to content\\n crewAI\\n Assembling and Activating Your CrewAI Team\\n crewAI\\n crewAI\\n crewAI\\n Home\\n Core Concepts\\n Core Concepts\\n Agents\\n Tasks\\n Tools\\n Processes\\n Crews\\n Collaboration\\n Memory\\n How to Guides\\n How to Guides\\n Installing CrewAI\\n Getting Started\\n Getting Started\\n Table of contents\\n Introduction\\n Step 0: Installation\\n Step 1: Assemble Your Agents\\n Step 2: Define the Tasks\\n Step 3: Form the Crew\\n Step 4: Kick It Off\\n Conclusion\\n Create Custom Tools\\n Using Sequential Process\\n Using Hierarchical Process\\n Connecting to any LLM\\n Customizing Agents\\n Human Input on Execution\\n Agent Monitoring with AgentOps\\n Tools Docs\\n Tools Docs\\n Google Serper Search\\n Browserbase Web Loader\\n Scrape Website\\n Directory Read\\n File Read\\n Selenium Scraper\\n Directory RAG Search\\n PDF RAG Search\\n TXT RAG Search\\n CSV RAG Search\\n XML RAG Search\\n JSON RAG Search\\n Docx Rag Search\\n MDX RAG Search\\n PG RAG Search\\n Website RAG Search\\n Github RAG Search\\n Code Docs RAG Search\\n Youtube Video RAG Search\\n Youtube Channel RAG Search\\n Examples\\n Examples\\n Trip Planner Crew\\n Create Instagram Post\\n Stock Analysis\\n Game Generator\\n Drafting emails with LangGraph\\n Landing Page Generator\\n Prepare for meetings\\n Telemetry\\nGetting Started\\nIntroduction¶\\nEmbark on your CrewAI journey by setting up your environment and initiating your AI crew with the latest features. This guide ensures a smooth start, incorporating all recent updates for an enhanced experience.\\nStep 0: Installation¶\\nInstall CrewAI and any necessary packages for your project. CrewAI is compatible with Python >=3.10,<=3.13.\\npip install crewai\\npip install \\'crewai[tools]\\'\\nStep 1: Assemble Your Agents¶\\nDefine your agents with distinct roles, backstories, and enhanced capabilities like verbose mode and memory usage. These elements add depth and guide their task execution and interaction within the crew.\\nimport os\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\\nfrom crewai import Agent\\nfrom crewai_tools import SerperDevTool\\nsearch_tool = SerperDevTool()\\n# Creating a senior researcher agent with memory and verbose mode\\nresearcher = Agent(\\n role=\\'Senior Researcher\\',\\n goal=\\'Uncover groundbreaking technologies in {topic}\\',\\n verbose=True,\\n memory=True,\\n backstory=(\\n \"Driven by curiosity, you\\'re at the forefront of\"\\n \"innovation, eager to explore and share knowledge that could change\"\\n \"the world.\"\\n ),\\n tools=[search_tool],\\n allow_delegation=True\\n)\\n# Creating a writer agent with custom tools and delegation capability\\nwriter = Agent(\\n role=\\'Writer\\',\\n goal=\\'Narrate compelling tech stories about {topic}\\',\\n verbose=True,\\n memory=True,\\n backstory=(\\n \"With a flair for simplifying complex topics, you craft\"\\n \"engaging narratives that captivate and educate, bringing new\"\\n \"discoveries to light in an accessible manner.\"\\n ),\\n tools=[search_tool],\\n allow_delegation=False\\n)\\nStep 2: Define the Tasks¶\\nDetail the specific objectives for your agents, including new features for asynchronous execution and output customization. These tasks ensure a targeted approach to their roles.\\nfrom crewai import Task\\n# Research task\\nresearch_task = Task(\\n description=(\\n \"Identify the next big trend in {topic}.\"\\n \"Focus on identifying pros and cons and the overall narrative.\"\\n \"Your final report should clearly articulate the key points,\"\\n \"its market opportunities, and potential risks.\"\\n ),\\n expected_output=\\'A comprehensive 3 paragraphs long report on the latest AI trends.\\',\\n tools=[search_tool],\\n agent=researcher,\\n)\\n# Writing task with language model configuration\\nwrite_task = Task(\\n description=(\\n \"Compose an insightful article on {topic}.\"\\n \"Focus on the latest trends and how it\\'s impacting the industry.\"\\n \"This article should be easy to understand, engaging, and positive.\"\\n ),\\n expected_output=\\'A 4 paragraph article on {topic} advancements formatted as markdown.\\',\\n tools=[search_tool],\\n agent=writer,\\n async_execution=False,\\n output_file=\\'new-blog-post.md\\' # Example of output customization\\n)\\nStep 3: Form the Crew¶\\nCombine your agents into a crew, setting the workflow process they\\'ll follow to accomplish the tasks. Now with options to configure language models for enhanced interaction and additional configurations for optimizing performance.\\nfrom crewai import Crew, Process\\n# Forming the tech-focused crew with some enhanced configurations\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[research_task, write_task],\\n process=Process.sequential, # Optional: Sequential task execution is default\\n memory=True,\\n cache=True,\\n max_rpm=100,\\n share_crew=True\\n)\\nStep 4: Kick It Off¶\\nInitiate the process with your enhanced crew ready. Observe as your agents collaborate, leveraging their new capabilities for a successful project outcome. Input variables will be interpolated into the agents and tasks for a personalized approach.\\n# Starting the task execution process with enhanced feedback\\nresult = crew.kickoff(inputs={\\'topic\\': \\'AI in healthcare\\'})\\nprint(result)\\nConclusion¶\\nBuilding and activating a crew in CrewAI has evolved with new functionalities. By incorporating verbose mode, memory capabilities, asynchronous task execution, output customization, language model configuration, and enhanced crew configurations, your AI team is more equipped than ever to tackle challenges efficiently. The depth of agent backstories and the precision of their objectives enrich collaboration, leading to successful project outcomes. This guide aims to provide you with a clear and detailed understanding of setting up and utilizing the CrewAI framework to its full potential.\\n Back to top\\n Previous\\n Installing CrewAI\\n Next\\n Create Custom Tools\\n Copyright © 2024 crewAI, Inc\\n Made with\\n Material for MkDocs'}\n",
      "\n",
      "Subtask identified: Summarise the extracted information from the website\n",
      "Getting LLM to perform the following task: Summarise the extracted information from the website\n",
      "> The website provides a detailed guide on how to assemble and activate your CrewAI team. It includes steps such as installation, assembling agents with distinct roles, defining tasks, forming the crew, and kicking off the process. The guide emphasizes the importance of incorporating new features like memory capabilities, asynchronous task execution, output customization, and language model configuration to enhance the efficiency of your AI team. By following these steps, users can build a well-equipped AI team capable of tackling challenges effectively.\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Assembling and Activating Your CrewAI Team - crewAI\\n Skip to content\\n crewAI\\n Assembling and Activating Your CrewAI Team\\n crewAI\\n crewAI\\n crewAI\\n Home\\n Core Concepts\\n Core Concepts\\n Agents\\n Tasks\\n Tools\\n Processes\\n Crews\\n Collaboration\\n Memory\\n How to Guides\\n How to Guides\\n Installing CrewAI\\n Getting Started\\n Getting Started\\n Table of contents\\n Introduction\\n Step 0: Installation\\n Step 1: Assemble Your Agents\\n Step 2: Define the Tasks\\n Step 3: Form the Crew\\n Step 4: Kick It Off\\n Conclusion\\n Create Custom Tools\\n Using Sequential Process\\n Using Hierarchical Process\\n Connecting to any LLM\\n Customizing Agents\\n Human Input on Execution\\n Agent Monitoring with AgentOps\\n Tools Docs\\n Tools Docs\\n Google Serper Search\\n Browserbase Web Loader\\n Scrape Website\\n Directory Read\\n File Read\\n Selenium Scraper\\n Directory RAG Search\\n PDF RAG Search\\n TXT RAG Search\\n CSV RAG Search\\n XML RAG Search\\n JSON RAG Search\\n Docx Rag Search\\n MDX RAG Search\\n PG RAG Search\\n Website RAG Search\\n Github RAG Search\\n Code Docs RAG Search\\n Youtube Video RAG Search\\n Youtube Channel RAG Search\\n Examples\\n Examples\\n Trip Planner Crew\\n Create Instagram Post\\n Stock Analysis\\n Game Generator\\n Drafting emails with LangGraph\\n Landing Page Generator\\n Prepare for meetings\\n Telemetry\\nGetting Started\\nIntroduction¶\\nEmbark on your CrewAI journey by setting up your environment and initiating your AI crew with the latest features. This guide ensures a smooth start, incorporating all recent updates for an enhanced experience.\\nStep 0: Installation¶\\nInstall CrewAI and any necessary packages for your project. CrewAI is compatible with Python >=3.10,<=3.13.\\npip install crewai\\npip install \\'crewai[tools]\\'\\nStep 1: Assemble Your Agents¶\\nDefine your agents with distinct roles, backstories, and enhanced capabilities like verbose mode and memory usage. These elements add depth and guide their task execution and interaction within the crew.\\nimport os\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\nos.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\\nfrom crewai import Agent\\nfrom crewai_tools import SerperDevTool\\nsearch_tool = SerperDevTool()\\n# Creating a senior researcher agent with memory and verbose mode\\nresearcher = Agent(\\n role=\\'Senior Researcher\\',\\n goal=\\'Uncover groundbreaking technologies in {topic}\\',\\n verbose=True,\\n memory=True,\\n backstory=(\\n \"Driven by curiosity, you\\'re at the forefront of\"\\n \"innovation, eager to explore and share knowledge that could change\"\\n \"the world.\"\\n ),\\n tools=[search_tool],\\n allow_delegation=True\\n)\\n# Creating a writer agent with custom tools and delegation capability\\nwriter = Agent(\\n role=\\'Writer\\',\\n goal=\\'Narrate compelling tech stories about {topic}\\',\\n verbose=True,\\n memory=True,\\n backstory=(\\n \"With a flair for simplifying complex topics, you craft\"\\n \"engaging narratives that captivate and educate, bringing new\"\\n \"discoveries to light in an accessible manner.\"\\n ),\\n tools=[search_tool],\\n allow_delegation=False\\n)\\nStep 2: Define the Tasks¶\\nDetail the specific objectives for your agents, including new features for asynchronous execution and output customization. These tasks ensure a targeted approach to their roles.\\nfrom crewai import Task\\n# Research task\\nresearch_task = Task(\\n description=(\\n \"Identify the next big trend in {topic}.\"\\n \"Focus on identifying pros and cons and the overall narrative.\"\\n \"Your final report should clearly articulate the key points,\"\\n \"its market opportunities, and potential risks.\"\\n ),\\n expected_output=\\'A comprehensive 3 paragraphs long report on the latest AI trends.\\',\\n tools=[search_tool],\\n agent=researcher,\\n)\\n# Writing task with language model configuration\\nwrite_task = Task(\\n description=(\\n \"Compose an insightful article on {topic}.\"\\n \"Focus on the latest trends and how it\\'s impacting the industry.\"\\n \"This article should be easy to understand, engaging, and positive.\"\\n ),\\n expected_output=\\'A 4 paragraph article on {topic} advancements formatted as markdown.\\',\\n tools=[search_tool],\\n agent=writer,\\n async_execution=False,\\n output_file=\\'new-blog-post.md\\' # Example of output customization\\n)\\nStep 3: Form the Crew¶\\nCombine your agents into a crew, setting the workflow process they\\'ll follow to accomplish the tasks. Now with options to configure language models for enhanced interaction and additional configurations for optimizing performance.\\nfrom crewai import Crew, Process\\n# Forming the tech-focused crew with some enhanced configurations\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[research_task, write_task],\\n process=Process.sequential, # Optional: Sequential task execution is default\\n memory=True,\\n cache=True,\\n max_rpm=100,\\n share_crew=True\\n)\\nStep 4: Kick It Off¶\\nInitiate the process with your enhanced crew ready. Observe as your agents collaborate, leveraging their new capabilities for a successful project outcome. Input variables will be interpolated into the agents and tasks for a personalized approach.\\n# Starting the task execution process with enhanced feedback\\nresult = crew.kickoff(inputs={\\'topic\\': \\'AI in healthcare\\'})\\nprint(result)\\nConclusion¶\\nBuilding and activating a crew in CrewAI has evolved with new functionalities. By incorporating verbose mode, memory capabilities, asynchronous task execution, output customization, language model configuration, and enhanced crew configurations, your AI team is more equipped than ever to tackle challenges efficiently. The depth of agent backstories and the precision of their objectives enrich collaboration, leading to successful project outcomes. This guide aims to provide you with a clear and detailed understanding of setting up and utilizing the CrewAI framework to its full potential.\\n Back to top\\n Previous\\n Installing CrewAI\\n Next\\n Create Custom Tools\\n Copyright © 2024 crewAI, Inc\\n Made with\\n Material for MkDocs'},\n",
       " {'Output': 'The website provides a detailed guide on how to assemble and activate your CrewAI team. It includes steps such as installation, assembling agents with distinct roles, defining tasks, forming the crew, and kicking off the process. The guide emphasizes the importance of incorporating new features like memory capabilities, asynchronous task execution, output customization, and language model configuration to enhance the efficiency of your AI team. By following these steps, users can build a well-equipped AI team capable of tackling challenges effectively.'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Summarise \"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "910d658e-89e4-4530-972d-e4a37f9f2437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key imports needed for CrewAI include importing the Agent class and tools from crewai and crewai_tools packages, as well as importing Task, Crew, and Process from crewai. Additionally, importing necessary packages like os for setting environment variables is required for configuring agents and tasks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The key imports needed for CrewAI include importing the Agent class and tools from crewai and crewai_tools packages, as well as importing Task, Crew, and Process from crewai. Additionally, importing necessary packages like os for setting environment variables is required for configuring agents and tasks.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What are the key imports needed for CrewAI?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c8fbd4a-ab85-4e03-88cd-6e17924e8fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrewAI is compatible with Python versions >=3.10 and <=3.13. The installation step mentions the compatibility with Python >=3.10,<=3.13, indicating that the CrewAI package is designed to work with these specific versions of Python.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CrewAI is compatible with Python versions >=3.10 and <=3.13. The installation step mentions the compatibility with Python >=3.10,<=3.13, indicating that the CrewAI package is designed to work with these specific versions of Python.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What version of packages are they compatible with?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c8158-7cd7-4bdd-8402-40e55bb55566",
   "metadata": {},
   "source": [
    "# LangChain Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a529f507-3a54-497d-9c0c-3e5e1c12a308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e0f6992-0fb3-4124-82e2-41f8a299dabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import Agent\n",
    "agent = Agent('Math Whiz', 'Does calculations').assign_functions([add.func, multiply.func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e011a86-35f6-4922-803b-184f86c6a331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add\\nDescription: Adds <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\",\n",
       " \"Name: multiply\\nDescription: Multiplies <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5506cd63-51c5-43e6-99b4-d4068579d7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Multiply 3 and 5\n",
      "Calling function multiply with parameters {'a': 3, 'b': 5}\n",
      "> {'output_1': 15}\n",
      "\n",
      "Subtask identified: Add the result of the multiplication to 3\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 15}, {'output_1': 18}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Calculate 3*5+3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfcddc-b3cf-4d1c-8749-89827b901b06",
   "metadata": {},
   "source": [
    "# LangChain Community Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e866e88-8f0d-4aaf-a12e-ae7fb91dea3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wikipedia_tool(search_query: str) -> str:\n",
    "    ''' Uses search_query and returns text from wikipedia '''\n",
    "    from langchain.tools import WikipediaQueryRun\n",
    "    from langchain.utilities import WikipediaAPIWrapper\n",
    "    from langchain.agents import Tool\n",
    "\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    return wikipedia.run(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12493d87-7e25-4fab-b8d1-8d5799e3616a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Wiki Agent', 'Searches Wiki').assign_functions(wikipedia_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4cc46c-d2dc-40e0-b124-e5764d6ea058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Use the equipped function wikipedia_tool to search for LangChain on Wikipedia\n",
      "Calling function wikipedia_tool with parameters {'search_query': 'LangChain'}\n",
      "> {'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison → house, chat → cat, chien →\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison → house, chat → cat, chien →\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Get me information on LangChain', num_subtasks = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda84665-304f-4e22-94d9-dab271d909a1",
   "metadata": {},
   "source": [
    "# LlamaIndex Function Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7cad1e-abe9-4f13-9478-ccabd02338e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Usfeful for getting the weather for a given location.\"\"\"\n",
    "    return 'Sunny'\n",
    "    ...\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    # async_fn=aget_weather,  # optional!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dbfa06-9849-4864-b775-094bcf98e401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Weather Agent', 'Returns the Weather').assign_functions(tool.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366387df-b36c-44a1-b45a-fa6cd2b58fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: get_weather\\nDescription: Usfeful for getting the weather for a given <location: str>.\\nInput: ['location']\\nOutput: {'output_1': 'str'}\\n\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29544561-a87c-4190-ad87-9d9f4c3cb235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Use the get_weather function with \"Miami\" as the location input\n",
      "Calling function get_weather with parameters {'location': 'Miami'}\n",
      "> {'output_1': 'Sunny'}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Sunny'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What is the weather in Miami?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
