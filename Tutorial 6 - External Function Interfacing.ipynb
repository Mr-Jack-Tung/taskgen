{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa1e388-b8f4-4fa3-be5a-ba7c6caae038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 6 - External Function Interfacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75f665-03e3-48d9-bc70-fab5f0549424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install taskgen-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076adf5e-beb1-4b19-9078-34ab1b7d9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up API key and do the necessary imports\n",
    "import os\n",
    "from taskgen import *\n",
    "import random\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b9a5f-7e80-4a03-a822-8135b1f8da3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding Python Function directly to Function\n",
    "- You should write a docstring that describes the function and contains all the input variable names that are not `args`, `kwargs` or `shared_variables`\n",
    "- typing for inputs and outputs will be automatically converted to TaskGen `Function` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed33cbb-bc0e-45ca-b06b-68cdeb50a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\n",
    "    ''' Appends num1 to num_list '''\n",
    "    num_list.append(num1)\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca759a1-49bf-4d96-9494-f387c9526256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = Function(external_fn = add_number_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23d77ff-fd6d-4668-85a1-450278c881aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Appends <num1: int> to <num_list: list[int]> \n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'output_1': 'list[int]'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367956e-916b-441c-906c-892090eee051",
   "metadata": {},
   "source": [
    "# Adding Python Function directly to Agent\n",
    "- We can also assign the Python function directly to an Agent and it will automatically convert it to `Function` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e6c470-92a6-4fe1-8370-a9c74c1cf390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Math Whiz', 'Does Math Calculations').assign_functions([add_number_to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3b6747-64a5-4e9e-858c-cddd5e0de689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add_number_to_list\\nDescription:  Appends <num1: int> to <num_list: list[int]> \\nInput: ['num1', 'num_list']\\nOutput: {'output_1': 'list[int]'}\\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5238a9a6-a654-482c-811a-0f4c8d21f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Append the number 5 to the list [2, 4]\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "Subtask identified: Append 5 to [2, 4]\n",
      "Calling function add_number_to_list with parameters {'num1': 5, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 5]}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': [2, 4, 5]}, {'output_1': [2, 4, 5]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Append 5 to [2, 4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c8158-7cd7-4bdd-8402-40e55bb55566",
   "metadata": {},
   "source": [
    "# LangChain Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a529f507-3a54-497d-9c0c-3e5e1c12a308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e0f6992-0fb3-4124-82e2-41f8a299dabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import Agent\n",
    "agent = Agent('Math Whiz', 'Does calculations').assign_functions([add.func, multiply.func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e011a86-35f6-4922-803b-184f86c6a331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add\\nDescription: Adds <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\",\n",
       " \"Name: multiply\\nDescription: Multiplies <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5506cd63-51c5-43e6-99b4-d4068579d7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Multiply 3 and 5\n",
      "Calling function multiply with parameters {'a': 3, 'b': 5}\n",
      "> {'output_1': 15}\n",
      "\n",
      "Subtask identified: Add the result of the multiplication to 3\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 15}, {'output_1': 18}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Calculate 3*5+3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfcddc-b3cf-4d1c-8749-89827b901b06",
   "metadata": {},
   "source": [
    "# LangChain Community Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e866e88-8f0d-4aaf-a12e-ae7fb91dea3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wikipedia_tool(search_query: str) -> str:\n",
    "    ''' Uses search_query and returns text from wikipedia '''\n",
    "    from langchain.tools import WikipediaQueryRun\n",
    "    from langchain.utilities import WikipediaAPIWrapper\n",
    "    from langchain.agents import Tool\n",
    "\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    return wikipedia.run(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12493d87-7e25-4fab-b8d1-8d5799e3616a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Wiki Agent', 'Searches Wiki').assign_functions(wikipedia_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4cc46c-d2dc-40e0-b124-e5764d6ea058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Use the equipped function wikipedia_tool to search for LangChain on Wikipedia\n",
      "Calling function wikipedia_tool with parameters {'search_query': 'LangChain'}\n",
      "> {'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison → house, chat → cat, chien →\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.\\nA prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", or a longer statement including context, instructions, and conversation history. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as asking the model to complete \"maison → house, chat → cat, chien →\" (the expected response being dog), an approach called few-shot learning.\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\n\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Get me information on LangChain', num_subtasks = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda84665-304f-4e22-94d9-dab271d909a1",
   "metadata": {},
   "source": [
    "# LlamaIndex Function Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7cad1e-abe9-4f13-9478-ccabd02338e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Usfeful for getting the weather for a given location.\"\"\"\n",
    "    return 'Sunny'\n",
    "    ...\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    # async_fn=aget_weather,  # optional!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dbfa06-9849-4864-b775-094bcf98e401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Weather Agent', 'Returns the Weather').assign_functions(tool.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366387df-b36c-44a1-b45a-fa6cd2b58fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only when task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: get_weather\\nDescription: Usfeful for getting the weather for a given <location: str>.\\nInput: ['location']\\nOutput: {'output_1': 'str'}\\n\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29544561-a87c-4190-ad87-9d9f4c3cb235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask identified: Use the get_weather function with \"Miami\" as the location input\n",
      "Calling function get_weather with parameters {'location': 'Miami'}\n",
      "> {'output_1': 'Sunny'}\n",
      "\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Sunny'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What is the weather in Miami?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
