{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa1e388-b8f4-4fa3-be5a-ba7c6caae038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 6 - External Function Interfacing\n",
    "- There are many other existing Agentic Frameworks like Crew.ai, LangChain / LangGraph, LlamaIndex that have many pre-established tools\n",
    "- TaskGen provides an easy way to interface with them and input them directly into TaskGen Agents!\n",
    "\n",
    "- Future Works\n",
    "    - In the future, you can import main tools from other frameworks / TaskGen native tools via `tools.py`\n",
    "    - In the future, there will also be an easy way to upload / download TaskGen community-based tools via code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a75f665-03e3-48d9-bc70-fab5f0549424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install taskgen-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076adf5e-beb1-4b19-9078-34ab1b7d9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up API key and do the necessary imports\n",
    "import os\n",
    "from taskgen import *\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e6e4b-597e-497e-8434-753b1dd70240",
   "metadata": {},
   "source": [
    "# Define your own Custom LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "11c129ea-ff2c-4961-9545-a5913597d33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_llm(system_prompt: str, user_prompt: str):\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "2dc2d3e9-fcca-4098-a194-0903b7a57ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment: Positive'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_llm('You are a classifier to classify the sentiment of a sentence', 'It is a hot and sunny day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5409acd-6835-47f1-9adf-aff3bc514f46",
   "metadata": {},
   "source": [
    "# Overview of Function Interfacing with TaskGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b9a5f-7e80-4a03-a822-8135b1f8da3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Adding Python Function directly to Function\n",
    "- You should write a docstring that describes the function and contains all the input variable names that are not `args`, `kwargs` or `shared_variables`\n",
    "- typing for inputs and outputs will be automatically converted to TaskGen `Function` format\n",
    "\n",
    "- **Smart Function Generator**: Even if you miss out the input type, or miss out output type, or have docstring without all input variables, or no docstring, we will smartly generate something out for you and the function can still be converted automatically to a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "1ed33cbb-bc0e-45ca-b06b-68cdeb50a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\n",
    "    ''' Appends num1 to num_list '''\n",
    "    num_list.append(num1)\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "4e7a1664-691d-403e-9116-6c445657c43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = Function(external_fn = add_number_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "26ac5b13-97b6-4d89-90fc-3092a3256960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  Appends <num1: int> to <num_list: list[int]> \n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'output_1': 'list[int]'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "f808e8cd-6150-4317-96d0-cb8ca42fcc90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': [2, 3, 7]}"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(7, [2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367956e-916b-441c-906c-892090eee051",
   "metadata": {},
   "source": [
    "## 2. Adding Python Function directly to Agent\n",
    "- We can also assign the Python function directly to an Agent and it will automatically convert it to `Function` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "c3e6c470-92a6-4fe1-8370-a9c74c1cf390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Math Whiz', 'Does Math Calculations', llm = custom_llm).assign_functions([add_number_to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "ab3b6747-64a5-4e9e-858c-cddd5e0de689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: use_llm\n",
      "Description: For general tasks. Used only when no other function can do the task\n",
      "Input: []\n",
      "Output: {'Output': 'Output of LLM'}\n",
      "\n",
      "Name: end_task\n",
      "Description: Use only after task is completed\n",
      "Input: []\n",
      "Output: {}\n",
      "\n",
      "Name: add_number_to_list\n",
      "Description:  Appends <num1: int> to <num_list: list[int]> \n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'output_1': 'list[int]'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "5238a9a6-a654-482c-811a-0f4c8d21f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task of appending 7 to [2, 4], I need to use the 'add_number_to_list' function to add 7 to the list [2, 4].\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add 7 to the list [2, 4]\u001b[0m\n",
      "Calling function add_number_to_list with parameters {'num1': 7, 'num_list': [2, 4]}\n",
      "> {'output_1': [2, 4, 7]}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task is to append 7 to the list [2, 4]. One subtask has been completed successfully, which is adding 7 to the list.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the subtask of adding 7 to the list has been completed, the remaining task is to end the task. This can be done by using the \"end_task\" function.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': [2, 4, 7]}]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Append 7 to [2, 4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6a7b7-2fdb-407e-bd5c-3024c007a8a5",
   "metadata": {},
   "source": [
    "# CrewAI Structured Tools Interface with TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8455989c-b934-49ee-aaed-e3562002722a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "efb3295a-6db9-4511-b0ca-4efce7d31bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_pdf_tool(file_path: str, query: str):\n",
    "    ''' Queries a pdf file at file_path using query and returns the relevant content '''\n",
    "    from crewai_tools import PDFSearchTool\n",
    "    \n",
    "    return PDFSearchTool(pdf=file_path).run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "03b2f805-eddb-460a-af8d-55e9cf40348b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-21 13:08:37--  https://arxiv.org/pdf/2210.03629\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.67.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 633805 (619K) [application/pdf]\n",
      "Saving to: ‘react.pdf’\n",
      "\n",
      "react.pdf           100%[===================>] 618.95K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-05-21 13:08:37 (27.6 MB/s) - ‘react.pdf’ saved [633805/633805]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://arxiv.org/pdf/2210.03629 -O react.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d9c32bd7-2a4c-4ecd-8754-6f2eca657b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Search a PDF's content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Relevant Content:\\nReAct-IM is in\\n\\nand gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct , to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. 1 I NTRODUCTION A unique feature of human intelligence is the\\n\\nPublished as a conference paper at ICLR 2023 appear sparsely in the most relevant positions of a trajectory, so we let the language model decide the asynchronous occurrence of thoughts and actions for itself. Since decision making and reasoning capabilities are integrated into a large language model, ReAct enjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is straightforward as human annotators just type down their thoughts in language on top of their actions taken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail prompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought space and thought-action occurrence format, ReAct works for diverse tasks with distinct action spaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web navigation. C) Performant and robust :ReAct shows strong generalization to new task instances while'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pdf_tool('react.pdf', 'What is ReAct?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "07b6d1c3-92bf-4a40-ae0d-5c1bbfb38897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('PDF Query Agent', 'References react.pdf and answers a user query').assign_functions([query_pdf_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4371a03b-1e28-4931-954a-47e1c0f9676f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: use_llm\n",
      "Description: For general tasks. Used only when no other function can do the task\n",
      "Input: []\n",
      "Output: {'Output': 'Output of LLM'}\n",
      "\n",
      "Name: end_task\n",
      "Description: Use only after task is completed\n",
      "Input: []\n",
      "Output: {}\n",
      "\n",
      "Name: query_pdf_tool\n",
      "Description:  Queries a pdf file at <file_path: str> using <query: str> and returns the relevant content \n",
      "Input: ['file_path', 'query']\n",
      "Output: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "884e70b6-735c-4cc0-bd62-6117279c4b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: \u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To answer the question 'What is ReAct?', we need to refer to the react.pdf file to find the relevant information.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Query the react.pdf file to find the definition and information about ReAct.\u001b[0m\n",
      "Calling function query_pdf_tool with parameters {'file_path': 'react.pdf', 'query': 'ReAct'}\n",
      "Using Tool: Search a PDF's content\n",
      "> {'output_1': 'Relevant Content:\\nReAct-IM is in\\n\\nand gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct , to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. 1 I NTRODUCTION A unique feature of human intelligence is the\\n\\nPublished as a conference paper at ICLR 2023 appear sparsely in the most relevant positions of a trajectory, so we let the language model decide the asynchronous occurrence of thoughts and actions for itself. Since decision making and reasoning capabilities are integrated into a large language model, ReAct enjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is straightforward as human annotators just type down their thoughts in language on top of their actions taken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail prompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought space and thought-action occurrence format, ReAct works for diverse tasks with distinct action spaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web navigation. C) Performant and robust :ReAct shows strong generalization to new task instances while'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The query to the react.pdf file has provided relevant information about ReAct, including its definition and features.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Based on the information gathered from the react.pdf file, it seems that ReAct is a system that integrates decision making and reasoning capabilities into a large language model. It is designed to interact with external sources and demonstrate effectiveness in various tasks such as question answering, fact verification, and interactive decision making. The system aims to improve human interpretability and trustworthiness by generating human-like task-solving trajectories. To complete the assigned task, we need to provide a concise summary of ReAct.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Relevant Content:\\nReAct-IM is in\\n\\nand gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct , to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. 1 I NTRODUCTION A unique feature of human intelligence is the\\n\\nPublished as a conference paper at ICLR 2023 appear sparsely in the most relevant positions of a trajectory, so we let the language model decide the asynchronous occurrence of thoughts and actions for itself. Since decision making and reasoning capabilities are integrated into a large language model, ReAct enjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is straightforward as human annotators just type down their thoughts in language on top of their actions taken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail prompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought space and thought-action occurrence format, ReAct works for diverse tasks with distinct action spaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web navigation. C) Performant and robust :ReAct shows strong generalization to new task instances while'}]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('What is ReAct?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6d4c1687-5fbd-421d-a497-8c7fcb29a464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct is a unique approach that integrates decision making and reasoning capabilities into a large language model. It is designed to interact with a simple Wikipedia API and generate human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. ReAct is intuitive and easy to design, general and flexible, and performant and robust. It shows strong generalization to new task instances.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ReAct is a unique approach that integrates decision making and reasoning capabilities into a large language model. It is designed to interact with a simple Wikipedia API and generate human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. ReAct is intuitive and easy to design, general and flexible, and performant and robust. It shows strong generalization to new task instances.'"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2c37c1b-439b-4948-ba2b-e1266e394a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# just wrap the external tool within a function\n",
    "def scrape_website_tool(website_url: str) -> str:\n",
    "    ''' Scrapes data from website_url '''\n",
    "    # import the tool\n",
    "    from crewai_tools import ScrapeWebsiteTool\n",
    "    \n",
    "    # initialise the tool\n",
    "    docs_scrape_tool = ScrapeWebsiteTool(\n",
    "        website_url=website_url)\n",
    "    \n",
    "    # run the tool\n",
    "    return docs_scrape_tool.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "74d03606-5399-4056-9ed2-d8c7e6a262f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Website summariser', 'Scrapes and then uses LLM to summarise a website to the user', \n",
    "              summarise_subtasks_count = 5).assign_functions([scrape_website_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3605667-a7de-4051-918a-8d32cb008d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: use_llm\n",
      "Description: For general tasks. Used only when no other function can do the task\n",
      "Input: []\n",
      "Output: {'Output': 'Output of LLM'}\n",
      "\n",
      "Name: end_task\n",
      "Description: Use only after task is completed\n",
      "Input: []\n",
      "Output: {}\n",
      "\n",
      "Name: scrape_website_tool\n",
      "Description:  Scrapes data from <website_url: str> \n",
      "Input: ['website_url']\n",
      "Output: {'output_1': 'str'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9c23c8d1-0b4e-40d7-9dfd-12c69ac16016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, we need to gather information on the differences between TaskGen and CrewAI. This can be achieved by scraping the respective websites and then summarising the content using LLM.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Scrapes data from \"https://github.com/simbianai/taskgen\"\u001b[0m\n",
      "Calling function scrape_website_tool with parameters {'website_url': 'https://github.com/simbianai/taskgen'}\n",
      "Using Tool: Read website content\n",
      "> {'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n simbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n 10\\n Star\\n 76\\n Task-based Agentic Framework using StrictJSON as the core\\nLicense\\n MIT license\\n76\\n stars\\n10\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History98 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0PyGame_Essay_Creator.ipynbPyGame_Essay_Creator.ipynb\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_18May2024.ipynbTaskGen AMA_18May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.3.0\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion\\nfn_name - String. If provided, this will be the name of the function. Ohterwise, if external_fn is provided, it will be the name of external_fn. Otherwise, we will use LLM to generate a function name from the fn_description\\nkwargs - Dict. Additional arguments you would like to pass on to the strict_json function\\nOutputs:\\nJSON of output variables in a dictionary (similar to strict_json)\\nExample Internal LLM-Based Function\\n# Construct the function: var1 will be first input variable, var2 will be second input variable and so on\\nsentence_style = Function(fn_description = \\'Output a sentence with words <var1> and <var2> in the style of <var3>\\', output_format = {\\'output\\': \\'sentence\\'})\\n# Use the function\\nsentence_style(\\'ball\\', \\'dog\\', \\'happy\\') #var1, var2, var3\\nExample Output\\n{\\'output\\': \\'The happy dog chased the ball.\\'}\\nExample External Function\\ndef binary_to_decimal(x):\\n return int(str(x), 2)\\n# an external function with a single output variable, with an expressive variable description\\nb2d = Function(fn_description = \\'Convert input <x: a binary number in base 2> to base 10\\', output_format = {\\'output1\\': \\'x in base 10\\'},\\n external_fn = binary_to_decimal)\\n# Use the function\\nb2d(10) #x\\nExample Output\\n{\\'output1\\': 2}\\nExample fn_description inferred from type hints and docstring of External Function\\n# Docstring must provide all input variables\\n# We will ignore shared_variables, *args and **kwargs\\nfrom typing import List\\ndef add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\\n \\'\\'\\'Adds num1 to num_list\\'\\'\\'\\n num_list.append(num1)\\n return num_list\\nfn = Function(external_fn = add_number_to_list, #output_format = {\\'num_array\\': \\'Array of numbers\\'} ## If you would like to name output variables (helps with LLM understanding), define your own output_format\\n )\\nstr(fn)\\nExample Output\\nDescription: Adds Adds <num1: int> to <num_list: list[int]>\\nInput: [\\'num1\\', \\'num_list\\']\\nOutput: {\\'output_1\\': \\'list[int]\\'}\\nPower Up your Agents - Bring in Functions (aka Tools)\\nAfter creating your agent, use assign_functions to assign a list of functions (of class Function) to it\\nFunction names will be automatically inferred if not specified\\nProceed to run tasks by using run()\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nmy_agent.assign_functions([sentence_style, b2d])\\noutput = my_agent.run(\\'Generate me a happy sentence with a number and a ball. The number is 1001 converted to decimal\\')\\nSubtask identified: Convert the binary number 1001 to decimal\\nCalling function binary_to_decimal with parameters {\\'x\\': \\'1001\\'}\\n{\\'output1\\': 9}\\nSubtask identified: Generate a happy sentence with the decimal number and a ball\\nCalling function sentence_with_objects_entities_emotion with parameters {\\'obj\\': \\'9\\', \\'entity\\': \\'ball\\', \\'emotion\\': \\'happy\\'}\\n{\\'output\\': \\'I am so happy with my 9 balls.\\'}\\nTask completed successfully!\\nSaving and Loading Agents\\nSometimes you want to configure your agents and save them and load them elsewhere, while maintaining the current agent state\\nWhen you use the save_agent function, we store the entire agent\\'s internal state, include name, description, list of functions, subtasks history and all other internal variables into a pickle file\\nWhen you use the load_agent function, and we will load the entire agent saved in the pickle file into the existing agent\\nKey functions:\\nsave_agent(pickle_file_name: str): Saves the agent\\'s internal parameters to a pickle file named pickle_file_name (include .pkl), returns the pickle file\\nload_agent(pickle_file_name: str): Loads the agent\\'s internal parameters from a pickle file named pickle_file_name (include .pkl), returns loaded agent\\nExample 1: Saving Agent\\nmy_agent.save_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent saved to myagent.pkl\\nExample 2: Loading Agent\\nnew_agent = Agent().load_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent loaded from myagent.pkl\\nInception: Agents within Agents - See Tutorial 2\\nYou can also create a Meta Agent that uses other Agents (referred to as Inner Agents) as functions\\nCreate your Meta agent using Agent() (Note: No different from usual process of creating Agents - your Meta Agent is also an Agent)\\nSet up an Inner Agent list and assign it to your Meta agent using assign_agents(agent_list)\\nExample Meta Agent Setup\\n# Define your meta-agent\\nmy_agent = Agent(\\'Menu Creator\\', \\'Creates a menu for a restaurant. Menu item includes Name, Description, Ingredients, Pricing.\\')\\n# Define your agent list. Note you can just assign functions to the agent in place using .assign_functions(function_list)\\nagent_list = [\\n Agent(\\'Chef\\', \\'Takes in dish names and comes up with ingredients for each of them. Does not generate prices.\\'),\\n Agent(\\'Boss\\', \\'\\'Does final quality check on menu items\\'),\\n Agent(\\'Creative Writer\\', \\'Takes in a cuisine type and generates interesting dish names and descriptions. Does not generate prices or ingredients.\\', max_subtasks = 2),\\n Agent(\\'Economist\\', \\'Takes in dish names and comes up with fictitious pricing for each of them\\')\\n ]\\nmy_agent.assign_agents(agent_list)\\nRun the Meta Agent\\nLet us run the agent and see the interactions between the Meta Agent and Inner Agents to solve the task!\\noutput = my_agent.run(\\'Give me 5 menu items with name, description, ingredients and price based on Italian food choices. Ensure all parts of menu are generated.\\')\\nShared Variables - See Tutorial 3\\n\"Because text is not enough\" - Anonymous\\nshared_variables is a dictionary, that is initialised in Agent (default empty dictionary), and can be referenced by any function of the agent (including Inner Agents and their functions)\\nThis can be useful for non-text modalitiies (e.g. audio, pdfs, image) and lengthy text modalities, which we do not want to output into subtasks_completed directly\\ns_ at the start of the variable names means shared variables\\nFor input, it means we take the variable from shared_variables instead of LLM generated input\\nFor output, it means we store the variable into shared_variables instead of storing it in subtasks_completed. If subtasks_completed output is empty, it will be output as {\\'Status\\': \\'Completed\\'}\\nExample shared variables names: s_sum, s_total, s_list_of_words\\nExample Input\\n# Function takes in increment (LLM generated) and s_total (retrieves from shared variable dict), and outputs to s_total (in shared variable dict)\\nadd = Function(fn_description = \"Add <increment: int> to <s_total>\", output_format = {\"s_total\": \"Modified total\"})\\n# Define the calculator agent and the shared_variables - Note the naming convention of s_ at the start of the names for shared variables\\nmy_agent = Agent(\\'Calculator\\', \\'Does computations\\', shared_variables = {\\'s_total\\': 0}).assign_functions([add])\\noutput = my_agent.run(\\'Increment total by 1\\')\\nprint(\\'Shared Variables:\\', my_agent.shared_variables)\\nExample Output\\nSubtask identified: Add 1 to the total\\nCalling function add_int_to_variable with parameters {\\'increment\\': 1}\\n{\\'Status\\': \\'Completed\\'}\\nTask completed successfully!\\nShared Variables: {\\'s_total\\': 1}\\nExample External Function Accessing Shared Variables (Advanced)\\n# Use shared_variables as input to your external function to access and modify the shared variables\\ndef generate_quotes(shared_variables, number_of_quotes: int, category: str):\\n \\'\\'\\' Generates number_of_quotes quotes about category \\'\\'\\'\\n # Retrieve from shared variables\\n my_quote_list = shared_variables[\\'quote_list\\']\\n ### Add your function code here ###\\n # Store back to shared variables\\n shared_variables[\\'quote_list\\'] = my_quote_list\\ngenerate_quote_fn = Function(output_format = {}, external_fn = generate_quotes)\\nMemory - See Tutorial 4\\nKey Philosophy\\nIt would be important to learn from past experience and improve the agentic framework - memory is key to that\\nYou can add to the memory bank of your Agents pre-inference (by collecting from a pool of data prior to running the Agent), or during inference (add on in between running subtasks)\\nUse Memory in Agents\\nAgent class takes memory_bank as a parameter during initialisation of an Agent\\nmemory_bank: class Dict[Memory]. Stores multiple types of memory for use by the agent. Customise the Memory config within the Memory class.\\nDefault: memory_bank = {\\'Function\\': Memory(top_k = 5, mapper = lambda x: x.fn_description, approach = \\'retrieve_by_ranker\\')}\\nKey: Function (Already Implemented Natively) - Does RAG over Task -> Function mapping\\nCan add in more keys that would fit your use case. Retrieves similar items to task/overall plan (if able) for additional context in get_next_subtasks() and use_llm() function\\nSide Note: RAG can also be done (and may be preferred) as a separate function of the Agent to retrieve more information when needed (so that we do not overload the Agent with information)\\nMemory Class\\nRetrieves top k memory items based on task\\nInputs:\\nmemory: List. Default: Empty List. The list containing the memory items\\ntop_k: Int. Default: 3. The number of memory list items to retrieve\\nmapper: Function. Maps the memory item to another form for comparison by ranker or LLM. Default: lambda x: x\\nExample mapping: lambda x: x.fn_description (If x is a Class and the string you want to compare for similarity is the fn_description attribute of that class)\\napproach: str. Either retrieve_by_ranker or retrieve_by_llm to retrieve memory items.\\nRanker is faster and cheaper as it compares via embeddings, but are inferior to LLM-based methods for context information\\nranker: Ranker. The Ranker which defines a similarity score between a query and a key. Default: OpenAI text-embedding-3-small model.\\nCan be replaced with a function which returns similarity score from 0 to 1 when given a query and key\\nExample Use Case\\nHelps to reduce number of functions present in LLM context for more accurate generation\\noutput = my_agent.run(\\'Calculate 2**10 * (5 + 1) / 10\\')\\nOriginal Function List: add_numbers, subtract_numbers, add_three_numbers, multiply_numbers, divide_numbers, power_of, GCD_of_two_numbers, modulo_of_numbers, absolute_difference, generate_poem_with_numbers, List_related_words, generate_quote\\nFiltered Function Names: add_three_numbers, multiply_numbers, divide_numbers, power_of, modulo_of_numbers\\nGlobal Context - See Tutorial 5 (Advanced)\\nAgent takes in one additional parameter: get_global_context\\nThis is a function that takes in the agent\\'s internal parameters (self) and outputs a string to the LLM to append to the prompts of any LLM-based calls internally, e.g. get_next_subtask, use_llm, reply_to_user\\nYou have full flexibility to access anything the agent knows and configure a global prompt to the agent\\nUses\\nUsed mainly to provide persistent variables to an agent that is not conveniently stored in subtasks_completed, e.g. ingredients remaining, location in grid for robot\\nImplementing your own specific instructions to the default planner prompt\\nImplement your own memory-based RAG / global prompt instruction if you need more than what the default prompt can achieve\\nAvoid Multiple Similar Subtasks in subtasks_history\\nIf you have multiple similar subtask names, then it is likely the Agent can be confused and think it has already done the subtask\\nIn this case, you can disambiguate by resetting the agent and store the persistent information in shared_variables and provide it to the agent using get_global_context\\nHas the benefit of shifting the Start State closer to End State desired by resetting the Agent\\'s planning cycle\\nKnown Limitations\\nTo be added\\nContributing to the project\\nTest locally\\nClone the repository\\nIf using a virtual environment, activate it\\ncd into taskgen repository\\nInstall the package via command line pip install -e .\\nNow you can import the package and use it in your code\\nSubmitting a pull request\\nFork the repository\\nCreate a new branch\\nMake your changes\\nPush your changes to your fork\\nSubmit a pull request\\nWhat are we looking out for?\\nIntegrations with functions - It would be good if we could import function definitions from elsewhere, e.g. LangChain, into the format shown here. It might even be done automatically using LLM-based conversion using StrictJSON!\\nJupyter Notebooks showcasing what could be done with the framework for something useful. Let your imagination guide you, we look forward to see what you create\\nOther Known Limitations - Do test the framework out extensively and note its failure cases. We will see if we can address them, if not we will put them in Known Limitations.\\n(For the prompt engineer). If you could find a better way to make the prompts work, let us know directly - we do need to test this out across all Tutorial Jupyter Notebooks to make sure that it really works with existing datasets. Also, if you are using other LLMs beside OpenAI, and find the prompts do not work as well - try to rejig your own prompts and let us know as well!\\nAbout\\n Task-based Agentic Framework using StrictJSON as the core\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nCustom properties\\nStars\\n76\\n stars\\nWatchers\\n4\\n watching\\nForks\\n10\\n forks\\n Report repository\\n Releases\\nNo releases published\\n Packages\\n 0\\n No packages published Contributors\\n 3\\nLanguages\\nJupyter Notebook\\n97.2%\\nPython\\n2.8%\\nFooter\\n © 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You can’t perform that action at this time.'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The differences between TaskGen and CrewAI have been explored by scraping the website of TaskGen and summarizing its features and functionalities.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the Assigned Task, we need to scrape the website of CrewAI and summarize its features and functionalities. This will allow us to compare the information gathered from both websites and highlight the distinctions between TaskGen and CrewAI.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Scrape data from \"https://github.com/joaomdmoura/CrewAI\"\u001b[0m\n",
      "Calling function scrape_website_tool with parameters {'website_url': 'https://github.com/joaomdmoura/CrewAI'}\n",
      "Using Tool: Read website content\n",
      "> {'output_1': 'GitHub - joaomdmoura/crewAI: Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n joaomdmoura\\n/\\ncrewAI\\nPublic\\nNotifications\\nFork\\n 1.9k\\n Star\\n 14.5k\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nLicense\\n MIT license\\n14.5k\\n stars\\n1.9k\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n304\\nPull requests\\n24\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\njoaomdmoura/crewAI\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History465 Commits.cache/plugin/social.cache/plugin/social\\xa0\\xa0.github/workflows.github/workflows\\xa0\\xa0docsdocs\\xa0\\xa0src/crewaisrc/crewai\\xa0\\xa0teststests\\xa0\\xa0.editorconfig.editorconfig\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0.pre-commit-config.yaml.pre-commit-config.yaml\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0crewAI.excalidrawcrewAI.excalidraw\\xa0\\xa0mkdocs.ymlmkdocs.yml\\xa0\\xa0poetry.lockpoetry.lock\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0View all filesRepository files navigationREADMEMIT license\\ncrewAI\\n🤖 crewAI: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nHomepage | Documentation | Chat with Docs | Examples | Discord\\nTable of contents\\nWhy CrewAI?\\nGetting Started\\nKey Features\\nExamples\\nQuick Tutorial\\nWrite Job Descriptions\\nTrip Planner\\nStock Analysis\\nConnecting Your Crew to a Model\\nHow CrewAI Compares\\nContribution\\nTelemetry\\nLicense\\nWhy CrewAI?\\nThe power of AI collaboration has too much to offer.\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you\\'re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\nGetting Started\\nTo get started with CrewAI, follow these simple steps:\\n1. Installation\\npip install crewai\\nIf you want to install the \\'crewai\\' package along with its optional features that include additional tools for agents, you can do so by using the following command: pip install \\'crewai[tools]\\'. This command installs the basic package and also adds extra components which require more dependencies to function.\"\\npip install \\'crewai[tools]\\'\\n2. Setting Up Your Crew\\nimport os\\nfrom crewai import Agent, Task, Crew, Process\\nfrom crewai_tools import SerperDevTool\\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\n# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.\\n# os.environ[\"OPENAI_API_BASE\"] = \\'http://localhost:11434/v1\\'\\n# os.environ[\"OPENAI_MODEL_NAME\"] =\\'openhermes\\' # Adjust based on available model\\n# os.environ[\"OPENAI_API_KEY\"] =\\'sk-111111111111111111111111111111111111111111111111\\'\\nsearch_tool = SerperDevTool()\\n# Define your agents with roles and goals\\nresearcher = Agent(\\n role=\\'Senior Research Analyst\\',\\n goal=\\'Uncover cutting-edge developments in AI and data science\\',\\n backstory=\"\"\"You work at a leading tech think tank.\\n Your expertise lies in identifying emerging trends.\\n You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\\n verbose=True,\\n allow_delegation=False,\\n tools=[search_tool]\\n # You can pass an optional llm attribute specifying what model you wanna use.\\n # It can be a local model through Ollama / LM Studio or a remote\\n # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\\n #\\n # import os\\n # os.environ[\\'OPENAI_MODEL_NAME\\'] = \\'gpt-3.5-turbo\\'\\n #\\n # OR\\n #\\n # from langchain_openai import ChatOpenAI\\n # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\\n)\\nwriter = Agent(\\n role=\\'Tech Content Strategist\\',\\n goal=\\'Craft compelling content on tech advancements\\',\\n backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\\n You transform complex concepts into compelling narratives.\"\"\",\\n verbose=True,\\n allow_delegation=True\\n)\\n# Create tasks for your agents\\ntask1 = Task(\\n description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\\n Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\\n expected_output=\"Full analysis report in bullet points\",\\n agent=researcher\\n)\\ntask2 = Task(\\n description=\"\"\"Using the insights provided, develop an engaging blog\\n post that highlights the most significant AI advancements.\\n Your post should be informative yet accessible, catering to a tech-savvy audience.\\n Make it sound cool, avoid complex words so it doesn\\'t sound like AI.\"\"\",\\n expected_output=\"Full blog post of at least 4 paragraphs\",\\n agent=writer\\n)\\n# Instantiate your crew with a sequential process\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[task1, task2],\\n verbose=2, # You can set it to 1 or 2 to different logging levels\\n)\\n# Get your crew to work!\\nresult = crew.kickoff()\\nprint(\"######################\")\\nprint(result)\\nIn addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. See more about the processes here.\\nKey Features\\nRole-Based Agent Design: Customize agents with specific roles, goals, and tools.\\nAutonomous Inter-Agent Delegation: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.\\nFlexible Task Management: Define tasks with customizable tools and assign them to agents dynamically.\\nProcesses Driven: Currently only supports sequential task execution and hierarchical processes, but more complex processes like consensual and autonomous are being worked on.\\nSave output as file: Save the output of individual tasks as a file, so you can use it later.\\nParse output as Pydantic or Json: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.\\nWorks with Open Source Models: Run your crew using Open AI or open source models refer to the Connect crewAI to LLMs page for details on configuring your agents\\' connections to models, even ones running locally!\\nExamples\\nYou can test different real life examples of AI crews in the crewAI-examples repo:\\nLanding Page Generator\\nHaving Human input on the execution\\nTrip Planner\\nStock Analysis\\nQuick Tutorial\\nWrite Job Descriptions\\nCheck out code for this example or watch a video below:\\nTrip Planner\\nCheck out code for this example or watch a video below:\\nStock Analysis\\nCheck out code for this example or watch a video below:\\nConnecting Your Crew to a Model\\ncrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.\\nPlease refer to the Connect crewAI to LLMs page for details on configuring you agents\\' connections to models.\\nHow CrewAI Compares\\nAutogen: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents\\' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.\\nChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.\\nCrewAI\\'s Advantage: CrewAI is built with production in mind. It offers the flexibility of Autogen\\'s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI\\'s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.\\nContribution\\nCrewAI is open-source and we welcome contributions. If you\\'re looking to contribute, please:\\nFork the repository.\\nCreate a new branch for your feature.\\nAdd your feature or improvement.\\nSend a pull request.\\nWe appreciate your input!\\nInstalling Dependencies\\npoetry lock\\npoetry install\\nVirtual Env\\npoetry shell\\nPre-commit hooks\\npre-commit install\\nRunning Tests\\npoetry run pytest\\nRunning static type checks\\npoetry run mypy\\nPackaging\\npoetry build\\nInstalling Locally\\npip install dist/*.tar.gz\\nTelemetry\\nCrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.\\nThere is NO data being collected on the prompts, tasks descriptions agents backstories or goals nor tools usage, no API calls, nor responses nor any data that is being processed by the agents, nor any secrets and env vars.\\nData collected includes:\\nVersion of crewAI\\nSo we can understand how many users are using the latest version\\nVersion of Python\\nSo we can decide on what versions to better support\\nGeneral OS (e.g. number of CPUs, macOS/Windows/Linux)\\nSo we know what OS we should focus on and if we could build specific OS related features\\nNumber of agents and tasks in a crew\\nSo we make sure we are testing internally with similar use cases and educate people on the best practices\\nCrew Process being used\\nUnderstand where we should focus our efforts\\nIf Agents are using memory or allowing delegation\\nUnderstand if we improved the features or maybe even drop them\\nIf Tasks are being executed in parallel or sequentially\\nUnderstand if we should focus more on parallel execution\\nLanguage model being used\\nImproved support on most used languages\\nRoles of agents in a crew\\nUnderstand high level use cases so we can build better tools, integrations and examples about it\\nTools names available\\nUnderstand out of the publically available tools, which ones are being used the most so we can improve them\\nUsers can opt-in sharing the complete telemetry data by setting the share_crew attribute to True on their Crews.\\nLicense\\nCrewAI is released under the MIT License.\\nAbout\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nTopics\\n ai\\n agents\\n ai-agents\\n llms\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nStars\\n14.5k\\n stars\\nWatchers\\n174\\n watching\\nForks\\n1.9k\\n forks\\n Report repository\\n Releases\\n 35\\nv0.30.8\\n Latest\\nMay 14, 2024\\n + 34 releases\\n Packages\\n 0\\n No packages published Used by 1.1k\\n + 1,074\\n Contributors\\n 75\\n + 61 contributors\\nLanguages\\nPython\\n100.0%\\nFooter\\n © 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You can’t perform that action at this time.'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: Data has been scraped from both TaskGen and CrewAI repositories on GitHub, providing detailed information about each framework.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the task of identifying the differences between TaskGen and CrewAI, we can compare the key features, design principles, and functionalities of both frameworks. We need to analyze the information extracted from the scraped data to highlight the distinctions between TaskGen and CrewAI.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Compare the key features, design principles, and functionalities of TaskGen and CrewAI to identify the differences between the two frameworks.\u001b[0m\n",
      "Getting LLM to perform the following task: Compare the key features, design principles, and functionalities of TaskGen and CrewAI to identify the differences between the two frameworks.\n",
      "> TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: Key features, design principles, and functionalities of TaskGen and CrewAI have been compared to identify their differences.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Based on the comparison, the differences between TaskGen and CrewAI have been highlighted. To complete the remaining part of the Assigned Task, we need to summarize the key differences between TaskGen and CrewAI.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Summarize the key differences between TaskGen and CrewAI based on the comparison of their features, design principles, and functionalities.\u001b[0m\n",
      "Getting LLM to perform the following task: Summarize the key differences between TaskGen and CrewAI based on the comparison of their features, design principles, and functionalities.\n",
      "> TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The differences between TaskGen and CrewAI have been summarized based on their key features, design principles, and functionalities.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the Assigned Task, we need to provide a comparison of the key features, design principles, and functionalities of TaskGen and CrewAI. This comparison should highlight the unique aspects of each framework and how they cater to different needs in the AI domain. We can focus on aspects such as task execution efficiency, agent interactions, and overall framework flexibility.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Compare the key features, design principles, and functionalities of TaskGen and CrewAI to highlight their unique aspects and how they cater to different requirements in the AI domain.\u001b[0m\n",
      "Getting LLM to perform the following task: Compare the key features, design principles, and functionalities of TaskGen and CrewAI to highlight their unique aspects and how they cater to different requirements in the AI domain.\n",
      "> TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n simbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n 10\\n Star\\n 76\\n Task-based Agentic Framework using StrictJSON as the core\\nLicense\\n MIT license\\n76\\n stars\\n10\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History98 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0PyGame_Essay_Creator.ipynbPyGame_Essay_Creator.ipynb\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_18May2024.ipynbTaskGen AMA_18May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.3.0\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion\\nfn_name - String. If provided, this will be the name of the function. Ohterwise, if external_fn is provided, it will be the name of external_fn. Otherwise, we will use LLM to generate a function name from the fn_description\\nkwargs - Dict. Additional arguments you would like to pass on to the strict_json function\\nOutputs:\\nJSON of output variables in a dictionary (similar to strict_json)\\nExample Internal LLM-Based Function\\n# Construct the function: var1 will be first input variable, var2 will be second input variable and so on\\nsentence_style = Function(fn_description = \\'Output a sentence with words <var1> and <var2> in the style of <var3>\\', output_format = {\\'output\\': \\'sentence\\'})\\n# Use the function\\nsentence_style(\\'ball\\', \\'dog\\', \\'happy\\') #var1, var2, var3\\nExample Output\\n{\\'output\\': \\'The happy dog chased the ball.\\'}\\nExample External Function\\ndef binary_to_decimal(x):\\n return int(str(x), 2)\\n# an external function with a single output variable, with an expressive variable description\\nb2d = Function(fn_description = \\'Convert input <x: a binary number in base 2> to base 10\\', output_format = {\\'output1\\': \\'x in base 10\\'},\\n external_fn = binary_to_decimal)\\n# Use the function\\nb2d(10) #x\\nExample Output\\n{\\'output1\\': 2}\\nExample fn_description inferred from type hints and docstring of External Function\\n# Docstring must provide all input variables\\n# We will ignore shared_variables, *args and **kwargs\\nfrom typing import List\\ndef add_number_to_list(num1: int, num_list: List[int], *args, **kwargs) -> List[int]:\\n \\'\\'\\'Adds num1 to num_list\\'\\'\\'\\n num_list.append(num1)\\n return num_list\\nfn = Function(external_fn = add_number_to_list, #output_format = {\\'num_array\\': \\'Array of numbers\\'} ## If you would like to name output variables (helps with LLM understanding), define your own output_format\\n )\\nstr(fn)\\nExample Output\\nDescription: Adds Adds <num1: int> to <num_list: list[int]>\\nInput: [\\'num1\\', \\'num_list\\']\\nOutput: {\\'output_1\\': \\'list[int]\\'}\\nPower Up your Agents - Bring in Functions (aka Tools)\\nAfter creating your agent, use assign_functions to assign a list of functions (of class Function) to it\\nFunction names will be automatically inferred if not specified\\nProceed to run tasks by using run()\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nmy_agent.assign_functions([sentence_style, b2d])\\noutput = my_agent.run(\\'Generate me a happy sentence with a number and a ball. The number is 1001 converted to decimal\\')\\nSubtask identified: Convert the binary number 1001 to decimal\\nCalling function binary_to_decimal with parameters {\\'x\\': \\'1001\\'}\\n{\\'output1\\': 9}\\nSubtask identified: Generate a happy sentence with the decimal number and a ball\\nCalling function sentence_with_objects_entities_emotion with parameters {\\'obj\\': \\'9\\', \\'entity\\': \\'ball\\', \\'emotion\\': \\'happy\\'}\\n{\\'output\\': \\'I am so happy with my 9 balls.\\'}\\nTask completed successfully!\\nSaving and Loading Agents\\nSometimes you want to configure your agents and save them and load them elsewhere, while maintaining the current agent state\\nWhen you use the save_agent function, we store the entire agent\\'s internal state, include name, description, list of functions, subtasks history and all other internal variables into a pickle file\\nWhen you use the load_agent function, and we will load the entire agent saved in the pickle file into the existing agent\\nKey functions:\\nsave_agent(pickle_file_name: str): Saves the agent\\'s internal parameters to a pickle file named pickle_file_name (include .pkl), returns the pickle file\\nload_agent(pickle_file_name: str): Loads the agent\\'s internal parameters from a pickle file named pickle_file_name (include .pkl), returns loaded agent\\nExample 1: Saving Agent\\nmy_agent.save_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent saved to myagent.pkl\\nExample 2: Loading Agent\\nnew_agent = Agent().load_agent(\\'myagent.pkl\\')\\nExample Output\\nAgent loaded from myagent.pkl\\nInception: Agents within Agents - See Tutorial 2\\nYou can also create a Meta Agent that uses other Agents (referred to as Inner Agents) as functions\\nCreate your Meta agent using Agent() (Note: No different from usual process of creating Agents - your Meta Agent is also an Agent)\\nSet up an Inner Agent list and assign it to your Meta agent using assign_agents(agent_list)\\nExample Meta Agent Setup\\n# Define your meta-agent\\nmy_agent = Agent(\\'Menu Creator\\', \\'Creates a menu for a restaurant. Menu item includes Name, Description, Ingredients, Pricing.\\')\\n# Define your agent list. Note you can just assign functions to the agent in place using .assign_functions(function_list)\\nagent_list = [\\n Agent(\\'Chef\\', \\'Takes in dish names and comes up with ingredients for each of them. Does not generate prices.\\'),\\n Agent(\\'Boss\\', \\'\\'Does final quality check on menu items\\'),\\n Agent(\\'Creative Writer\\', \\'Takes in a cuisine type and generates interesting dish names and descriptions. Does not generate prices or ingredients.\\', max_subtasks = 2),\\n Agent(\\'Economist\\', \\'Takes in dish names and comes up with fictitious pricing for each of them\\')\\n ]\\nmy_agent.assign_agents(agent_list)\\nRun the Meta Agent\\nLet us run the agent and see the interactions between the Meta Agent and Inner Agents to solve the task!\\noutput = my_agent.run(\\'Give me 5 menu items with name, description, ingredients and price based on Italian food choices. Ensure all parts of menu are generated.\\')\\nShared Variables - See Tutorial 3\\n\"Because text is not enough\" - Anonymous\\nshared_variables is a dictionary, that is initialised in Agent (default empty dictionary), and can be referenced by any function of the agent (including Inner Agents and their functions)\\nThis can be useful for non-text modalitiies (e.g. audio, pdfs, image) and lengthy text modalities, which we do not want to output into subtasks_completed directly\\ns_ at the start of the variable names means shared variables\\nFor input, it means we take the variable from shared_variables instead of LLM generated input\\nFor output, it means we store the variable into shared_variables instead of storing it in subtasks_completed. If subtasks_completed output is empty, it will be output as {\\'Status\\': \\'Completed\\'}\\nExample shared variables names: s_sum, s_total, s_list_of_words\\nExample Input\\n# Function takes in increment (LLM generated) and s_total (retrieves from shared variable dict), and outputs to s_total (in shared variable dict)\\nadd = Function(fn_description = \"Add <increment: int> to <s_total>\", output_format = {\"s_total\": \"Modified total\"})\\n# Define the calculator agent and the shared_variables - Note the naming convention of s_ at the start of the names for shared variables\\nmy_agent = Agent(\\'Calculator\\', \\'Does computations\\', shared_variables = {\\'s_total\\': 0}).assign_functions([add])\\noutput = my_agent.run(\\'Increment total by 1\\')\\nprint(\\'Shared Variables:\\', my_agent.shared_variables)\\nExample Output\\nSubtask identified: Add 1 to the total\\nCalling function add_int_to_variable with parameters {\\'increment\\': 1}\\n{\\'Status\\': \\'Completed\\'}\\nTask completed successfully!\\nShared Variables: {\\'s_total\\': 1}\\nExample External Function Accessing Shared Variables (Advanced)\\n# Use shared_variables as input to your external function to access and modify the shared variables\\ndef generate_quotes(shared_variables, number_of_quotes: int, category: str):\\n \\'\\'\\' Generates number_of_quotes quotes about category \\'\\'\\'\\n # Retrieve from shared variables\\n my_quote_list = shared_variables[\\'quote_list\\']\\n ### Add your function code here ###\\n # Store back to shared variables\\n shared_variables[\\'quote_list\\'] = my_quote_list\\ngenerate_quote_fn = Function(output_format = {}, external_fn = generate_quotes)\\nMemory - See Tutorial 4\\nKey Philosophy\\nIt would be important to learn from past experience and improve the agentic framework - memory is key to that\\nYou can add to the memory bank of your Agents pre-inference (by collecting from a pool of data prior to running the Agent), or during inference (add on in between running subtasks)\\nUse Memory in Agents\\nAgent class takes memory_bank as a parameter during initialisation of an Agent\\nmemory_bank: class Dict[Memory]. Stores multiple types of memory for use by the agent. Customise the Memory config within the Memory class.\\nDefault: memory_bank = {\\'Function\\': Memory(top_k = 5, mapper = lambda x: x.fn_description, approach = \\'retrieve_by_ranker\\')}\\nKey: Function (Already Implemented Natively) - Does RAG over Task -> Function mapping\\nCan add in more keys that would fit your use case. Retrieves similar items to task/overall plan (if able) for additional context in get_next_subtasks() and use_llm() function\\nSide Note: RAG can also be done (and may be preferred) as a separate function of the Agent to retrieve more information when needed (so that we do not overload the Agent with information)\\nMemory Class\\nRetrieves top k memory items based on task\\nInputs:\\nmemory: List. Default: Empty List. The list containing the memory items\\ntop_k: Int. Default: 3. The number of memory list items to retrieve\\nmapper: Function. Maps the memory item to another form for comparison by ranker or LLM. Default: lambda x: x\\nExample mapping: lambda x: x.fn_description (If x is a Class and the string you want to compare for similarity is the fn_description attribute of that class)\\napproach: str. Either retrieve_by_ranker or retrieve_by_llm to retrieve memory items.\\nRanker is faster and cheaper as it compares via embeddings, but are inferior to LLM-based methods for context information\\nranker: Ranker. The Ranker which defines a similarity score between a query and a key. Default: OpenAI text-embedding-3-small model.\\nCan be replaced with a function which returns similarity score from 0 to 1 when given a query and key\\nExample Use Case\\nHelps to reduce number of functions present in LLM context for more accurate generation\\noutput = my_agent.run(\\'Calculate 2**10 * (5 + 1) / 10\\')\\nOriginal Function List: add_numbers, subtract_numbers, add_three_numbers, multiply_numbers, divide_numbers, power_of, GCD_of_two_numbers, modulo_of_numbers, absolute_difference, generate_poem_with_numbers, List_related_words, generate_quote\\nFiltered Function Names: add_three_numbers, multiply_numbers, divide_numbers, power_of, modulo_of_numbers\\nGlobal Context - See Tutorial 5 (Advanced)\\nAgent takes in one additional parameter: get_global_context\\nThis is a function that takes in the agent\\'s internal parameters (self) and outputs a string to the LLM to append to the prompts of any LLM-based calls internally, e.g. get_next_subtask, use_llm, reply_to_user\\nYou have full flexibility to access anything the agent knows and configure a global prompt to the agent\\nUses\\nUsed mainly to provide persistent variables to an agent that is not conveniently stored in subtasks_completed, e.g. ingredients remaining, location in grid for robot\\nImplementing your own specific instructions to the default planner prompt\\nImplement your own memory-based RAG / global prompt instruction if you need more than what the default prompt can achieve\\nAvoid Multiple Similar Subtasks in subtasks_history\\nIf you have multiple similar subtask names, then it is likely the Agent can be confused and think it has already done the subtask\\nIn this case, you can disambiguate by resetting the agent and store the persistent information in shared_variables and provide it to the agent using get_global_context\\nHas the benefit of shifting the Start State closer to End State desired by resetting the Agent\\'s planning cycle\\nKnown Limitations\\nTo be added\\nContributing to the project\\nTest locally\\nClone the repository\\nIf using a virtual environment, activate it\\ncd into taskgen repository\\nInstall the package via command line pip install -e .\\nNow you can import the package and use it in your code\\nSubmitting a pull request\\nFork the repository\\nCreate a new branch\\nMake your changes\\nPush your changes to your fork\\nSubmit a pull request\\nWhat are we looking out for?\\nIntegrations with functions - It would be good if we could import function definitions from elsewhere, e.g. LangChain, into the format shown here. It might even be done automatically using LLM-based conversion using StrictJSON!\\nJupyter Notebooks showcasing what could be done with the framework for something useful. Let your imagination guide you, we look forward to see what you create\\nOther Known Limitations - Do test the framework out extensively and note its failure cases. We will see if we can address them, if not we will put them in Known Limitations.\\n(For the prompt engineer). If you could find a better way to make the prompts work, let us know directly - we do need to test this out across all Tutorial Jupyter Notebooks to make sure that it really works with existing datasets. Also, if you are using other LLMs beside OpenAI, and find the prompts do not work as well - try to rejig your own prompts and let us know as well!\\nAbout\\n Task-based Agentic Framework using StrictJSON as the core\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nCustom properties\\nStars\\n76\\n stars\\nWatchers\\n4\\n watching\\nForks\\n10\\n forks\\n Report repository\\n Releases\\nNo releases published\\n Packages\\n 0\\n No packages published Contributors\\n 3\\nLanguages\\nJupyter Notebook\\n97.2%\\nPython\\n2.8%\\nFooter\\n © 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You can’t perform that action at this time.'},\n",
       " {'output_1': 'GitHub - joaomdmoura/crewAI: Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nSkip to content\\nNavigation Menu\\nToggle navigation\\n Sign in\\n Product\\nActions\\n Automate any workflow\\nPackages\\n Host and manage packages\\nSecurity\\n Find and fix vulnerabilities\\nCodespaces\\n Instant dev environments\\nCopilot\\n Write better code with AI\\nCode review\\n Manage code changes\\nIssues\\n Plan and track work\\nDiscussions\\n Collaborate outside of code\\nExplore\\n All features\\n Documentation\\n GitHub Skills\\n Blog\\n Solutions\\nFor\\n Enterprise\\n Teams\\n Startups\\n Education\\nBy Solution\\n CI/CD & Automation\\n DevOps\\n DevSecOps\\nResources\\n Learning Pathways\\n White papers, Ebooks, Webinars\\n Customer Stories\\n Partners\\n Open Source\\nGitHub Sponsors\\n Fund open source developers\\nThe ReadME Project\\n GitHub community articles\\nRepositories\\n Topics\\n Trending\\n Collections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\n Search\\nClear\\n Search syntax tips\\n Provide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\n Cancel\\n Submit feedback\\n Saved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\n To see all available qualifiers, see our documentation.\\n Cancel\\n Create saved search\\n Sign in\\n Sign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\n joaomdmoura\\n/\\ncrewAI\\nPublic\\nNotifications\\nFork\\n 1.9k\\n Star\\n 14.5k\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nLicense\\n MIT license\\n14.5k\\n stars\\n1.9k\\n forks\\nBranches\\nTags\\nActivity\\n Star\\nNotifications\\nCode\\nIssues\\n304\\nPull requests\\n24\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\n Code\\n Issues\\n Pull requests\\n Actions\\n Projects\\n Security\\n Insights\\njoaomdmoura/crewAI\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History465 Commits.cache/plugin/social.cache/plugin/social\\xa0\\xa0.github/workflows.github/workflows\\xa0\\xa0docsdocs\\xa0\\xa0src/crewaisrc/crewai\\xa0\\xa0teststests\\xa0\\xa0.editorconfig.editorconfig\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0.pre-commit-config.yaml.pre-commit-config.yaml\\xa0\\xa0LICENSELICENSE\\xa0\\xa0README.mdREADME.md\\xa0\\xa0crewAI.excalidrawcrewAI.excalidraw\\xa0\\xa0mkdocs.ymlmkdocs.yml\\xa0\\xa0poetry.lockpoetry.lock\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0View all filesRepository files navigationREADMEMIT license\\ncrewAI\\n🤖 crewAI: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\nHomepage | Documentation | Chat with Docs | Examples | Discord\\nTable of contents\\nWhy CrewAI?\\nGetting Started\\nKey Features\\nExamples\\nQuick Tutorial\\nWrite Job Descriptions\\nTrip Planner\\nStock Analysis\\nConnecting Your Crew to a Model\\nHow CrewAI Compares\\nContribution\\nTelemetry\\nLicense\\nWhy CrewAI?\\nThe power of AI collaboration has too much to offer.\\nCrewAI is designed to enable AI agents to assume roles, share goals, and operate in a cohesive unit - much like a well-oiled crew. Whether you\\'re building a smart assistant platform, an automated customer service ensemble, or a multi-agent research team, CrewAI provides the backbone for sophisticated multi-agent interactions.\\nGetting Started\\nTo get started with CrewAI, follow these simple steps:\\n1. Installation\\npip install crewai\\nIf you want to install the \\'crewai\\' package along with its optional features that include additional tools for agents, you can do so by using the following command: pip install \\'crewai[tools]\\'. This command installs the basic package and also adds extra components which require more dependencies to function.\"\\npip install \\'crewai[tools]\\'\\n2. Setting Up Your Crew\\nimport os\\nfrom crewai import Agent, Task, Crew, Process\\nfrom crewai_tools import SerperDevTool\\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\\nos.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\\n# You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.\\n# os.environ[\"OPENAI_API_BASE\"] = \\'http://localhost:11434/v1\\'\\n# os.environ[\"OPENAI_MODEL_NAME\"] =\\'openhermes\\' # Adjust based on available model\\n# os.environ[\"OPENAI_API_KEY\"] =\\'sk-111111111111111111111111111111111111111111111111\\'\\nsearch_tool = SerperDevTool()\\n# Define your agents with roles and goals\\nresearcher = Agent(\\n role=\\'Senior Research Analyst\\',\\n goal=\\'Uncover cutting-edge developments in AI and data science\\',\\n backstory=\"\"\"You work at a leading tech think tank.\\n Your expertise lies in identifying emerging trends.\\n You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\\n verbose=True,\\n allow_delegation=False,\\n tools=[search_tool]\\n # You can pass an optional llm attribute specifying what model you wanna use.\\n # It can be a local model through Ollama / LM Studio or a remote\\n # model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)\\n #\\n # import os\\n # os.environ[\\'OPENAI_MODEL_NAME\\'] = \\'gpt-3.5-turbo\\'\\n #\\n # OR\\n #\\n # from langchain_openai import ChatOpenAI\\n # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\\n)\\nwriter = Agent(\\n role=\\'Tech Content Strategist\\',\\n goal=\\'Craft compelling content on tech advancements\\',\\n backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\\n You transform complex concepts into compelling narratives.\"\"\",\\n verbose=True,\\n allow_delegation=True\\n)\\n# Create tasks for your agents\\ntask1 = Task(\\n description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\\n Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\\n expected_output=\"Full analysis report in bullet points\",\\n agent=researcher\\n)\\ntask2 = Task(\\n description=\"\"\"Using the insights provided, develop an engaging blog\\n post that highlights the most significant AI advancements.\\n Your post should be informative yet accessible, catering to a tech-savvy audience.\\n Make it sound cool, avoid complex words so it doesn\\'t sound like AI.\"\"\",\\n expected_output=\"Full blog post of at least 4 paragraphs\",\\n agent=writer\\n)\\n# Instantiate your crew with a sequential process\\ncrew = Crew(\\n agents=[researcher, writer],\\n tasks=[task1, task2],\\n verbose=2, # You can set it to 1 or 2 to different logging levels\\n)\\n# Get your crew to work!\\nresult = crew.kickoff()\\nprint(\"######################\")\\nprint(result)\\nIn addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. See more about the processes here.\\nKey Features\\nRole-Based Agent Design: Customize agents with specific roles, goals, and tools.\\nAutonomous Inter-Agent Delegation: Agents can autonomously delegate tasks and inquire amongst themselves, enhancing problem-solving efficiency.\\nFlexible Task Management: Define tasks with customizable tools and assign them to agents dynamically.\\nProcesses Driven: Currently only supports sequential task execution and hierarchical processes, but more complex processes like consensual and autonomous are being worked on.\\nSave output as file: Save the output of individual tasks as a file, so you can use it later.\\nParse output as Pydantic or Json: Parse the output of individual tasks as a Pydantic model or as a Json if you want to.\\nWorks with Open Source Models: Run your crew using Open AI or open source models refer to the Connect crewAI to LLMs page for details on configuring your agents\\' connections to models, even ones running locally!\\nExamples\\nYou can test different real life examples of AI crews in the crewAI-examples repo:\\nLanding Page Generator\\nHaving Human input on the execution\\nTrip Planner\\nStock Analysis\\nQuick Tutorial\\nWrite Job Descriptions\\nCheck out code for this example or watch a video below:\\nTrip Planner\\nCheck out code for this example or watch a video below:\\nStock Analysis\\nCheck out code for this example or watch a video below:\\nConnecting Your Crew to a Model\\ncrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.\\nPlease refer to the Connect crewAI to LLMs page for details on configuring you agents\\' connections to models.\\nHow CrewAI Compares\\nAutogen: While Autogen does good in creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents\\' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.\\nChatDev: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.\\nCrewAI\\'s Advantage: CrewAI is built with production in mind. It offers the flexibility of Autogen\\'s conversational agents and the structured process approach of ChatDev, but without the rigidity. CrewAI\\'s processes are designed to be dynamic and adaptable, fitting seamlessly into both development and production workflows.\\nContribution\\nCrewAI is open-source and we welcome contributions. If you\\'re looking to contribute, please:\\nFork the repository.\\nCreate a new branch for your feature.\\nAdd your feature or improvement.\\nSend a pull request.\\nWe appreciate your input!\\nInstalling Dependencies\\npoetry lock\\npoetry install\\nVirtual Env\\npoetry shell\\nPre-commit hooks\\npre-commit install\\nRunning Tests\\npoetry run pytest\\nRunning static type checks\\npoetry run mypy\\nPackaging\\npoetry build\\nInstalling Locally\\npip install dist/*.tar.gz\\nTelemetry\\nCrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.\\nThere is NO data being collected on the prompts, tasks descriptions agents backstories or goals nor tools usage, no API calls, nor responses nor any data that is being processed by the agents, nor any secrets and env vars.\\nData collected includes:\\nVersion of crewAI\\nSo we can understand how many users are using the latest version\\nVersion of Python\\nSo we can decide on what versions to better support\\nGeneral OS (e.g. number of CPUs, macOS/Windows/Linux)\\nSo we know what OS we should focus on and if we could build specific OS related features\\nNumber of agents and tasks in a crew\\nSo we make sure we are testing internally with similar use cases and educate people on the best practices\\nCrew Process being used\\nUnderstand where we should focus our efforts\\nIf Agents are using memory or allowing delegation\\nUnderstand if we improved the features or maybe even drop them\\nIf Tasks are being executed in parallel or sequentially\\nUnderstand if we should focus more on parallel execution\\nLanguage model being used\\nImproved support on most used languages\\nRoles of agents in a crew\\nUnderstand high level use cases so we can build better tools, integrations and examples about it\\nTools names available\\nUnderstand out of the publically available tools, which ones are being used the most so we can improve them\\nUsers can opt-in sharing the complete telemetry data by setting the share_crew attribute to True on their Crews.\\nLicense\\nCrewAI is released under the MIT License.\\nAbout\\n Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\\ncrewai.com\\nTopics\\n ai\\n agents\\n ai-agents\\n llms\\nResources\\n Readme\\nLicense\\n MIT license\\nActivity\\nStars\\n14.5k\\n stars\\nWatchers\\n174\\n watching\\nForks\\n1.9k\\n forks\\n Report repository\\n Releases\\n 35\\nv0.30.8\\n Latest\\nMay 14, 2024\\n + 34 releases\\n Packages\\n 0\\n No packages published Used by 1.1k\\n + 1,074\\n Contributors\\n 75\\n + 61 contributors\\nLanguages\\nPython\\n100.0%\\nFooter\\n © 2024 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\n Manage cookies\\n Do not share my personal information\\n You can’t perform that action at this time.'},\n",
       " {'Output': 'TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.'},\n",
       " {'Output': 'TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.'},\n",
       " {'Output': 'TaskGen and CrewAI are two distinct frameworks with unique features and design principles. TaskGen focuses on a task-based agentic framework using StrictJSON as the core, enabling efficient and targeted task execution. It emphasizes splitting tasks into subtasks, shared variables, and retrieval augmented generation for enhanced performance. On the other hand, CrewAI is designed for orchestrating role-playing autonomous AI agents, fostering collaborative intelligence for seamless task handling. It offers role-based agent design, autonomous inter-agent delegation, and flexible task management. While TaskGen excels in task efficiency and structured execution, CrewAI stands out for its collaborative agent interactions and dynamic process-driven approach.'}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What are the differences between TaskGen (\"https://github.com/simbianai/taskgen\") and CrewAI (\"https://github.com/joaomdmoura/CrewAI\")?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "910d658e-89e4-4530-972d-e4a37f9f2437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key imports needed for TaskGen include importing the required functions from taskgen and using them. For CrewAI, the key imports involve importing various modules such as Agent, Task, Crew, Process, and SerperDevTool from crewai and crewai_tools packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The key imports needed for TaskGen include importing the required functions from taskgen and using them. For CrewAI, the key imports involve importing various modules such as Agent, Task, Crew, Process, and SerperDevTool from crewai and crewai_tools packages.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What are the key imports needed?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3c8fbd4a-ab85-4e03-88cd-6e17924e8fdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskGen and CrewAI are compatible with different versions of packages. TaskGen requires the package \"taskgen-ai\" to be installed, which can be done using \"pip install taskgen-ai\". For CrewAI, the package \"crewai\" needs to be installed, and additional tools can be included by using \"pip install 'crewai[tools]'\". Both frameworks may have dependencies on specific versions of Python and other libraries, so it is essential to refer to their respective documentation for detailed compatibility information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TaskGen and CrewAI are compatible with different versions of packages. TaskGen requires the package \"taskgen-ai\" to be installed, which can be done using \"pip install taskgen-ai\". For CrewAI, the package \"crewai\" needs to be installed, and additional tools can be included by using \"pip install \\'crewai[tools]\\'\". Both frameworks may have dependencies on specific versions of Python and other libraries, so it is essential to refer to their respective documentation for detailed compatibility information.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user('What version of packages are they compatible with?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c8158-7cd7-4bdd-8402-40e55bb55566",
   "metadata": {},
   "source": [
    "# LangChain Structured Tools Interface with TaskGen\n",
    "- If User defines a function in LangChain, simply just add <fn_name>.func to TaskGen Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a529f507-3a54-497d-9c0c-3e5e1c12a308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4e0f6992-0fb3-4124-82e2-41f8a299dabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import Agent\n",
    "agent = Agent('Math Whiz', 'Does calculations').assign_functions([add.func, multiply.func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5e011a86-35f6-4922-803b-184f86c6a331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: For general tasks. Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only after task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: add\\nDescription: Adds <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\",\n",
       " \"Name: multiply\\nDescription: Multiplies <a: int> and <b: int>.\\nInput: ['a', 'b']\\nOutput: {'output_1': 'int'}\\n\"]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5506cd63-51c5-43e6-99b4-d4068579d7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To calculate 3*5+3, we need to first multiply 3 and 5, then add 3 to the result.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Multiply 3 and 5.\u001b[0m\n",
      "Calling function multiply with parameters {'a': 3, 'b': 5}\n",
      "> {'output_1': 15}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The task is to calculate 3*5+3. The subtask of multiplying 3 and 5 has been completed successfully.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the multiplication of 3 and 5 has been done, the next step is to add 3 to the result of the multiplication to complete the calculation. This can be achieved by using the \"add\" function with the result of the multiplication and 3 as inputs.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add 3 to the result of multiplying 3 and 5.\u001b[0m\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The Assigned Task is to calculate 3*5+3. Two subtasks have been completed: multiplying 3 and 5 to get 15, and adding 3 to the result of multiplying 3 and 5 to get 18.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the Assigned Task, we need to perform the final calculation of adding 3 to the result obtained from multiplying 3 and 5. Since the multiplication and addition have been done, the final step is to add 3 to the result. This can be achieved by using the \"add\" function with inputs a=15 and b=3.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Add 3 to the result obtained from multiplying 3 and 5.\u001b[0m\n",
      "Calling function add with parameters {'a': 15, 'b': 3}\n",
      "> {'output_1': 18}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The subtasks completed so far involve multiplying 3 and 5, adding 3 to the result of multiplying 3 and 5, and adding 3 to the result obtained from multiplying 3 and 5.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the assigned task, we need to calculate the final result by adding 3 to the result obtained from multiplying 3 and 5. Since we already have the result of the previous calculations, we can directly add 3 to it to get the final answer.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Adds 18 and 3.\u001b[0m\n",
      "Calling function add with parameters {'a': 18, 'b': 3}\n",
      "> {'output_1': 21}\n",
      "\n",
      "### Auto-summarising Subtasks Completed ###\n",
      "The calculation for 3*5+3 is already completed. The result is 18.\n",
      "### End of Auto-summary ###\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The calculation for 3*5+3 is already completed. The result is 18.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the calculation for 3*5+3 is already completed and the result is 18, the next step is to end the task.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The calculation for 3*5+3 is already completed. The result is 18.']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Calculate 3*5+3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfcddc-b3cf-4d1c-8749-89827b901b06",
   "metadata": {},
   "source": [
    "# LangChain Community Tools Interface with TaskGen\n",
    "- See https://python.langchain.com/v0.2/docs/integrations/providers/ for full list\n",
    "- Wikipedia\n",
    "- Python REPL (not that great to run many things - have created my own in TaskGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72872030-d4dc-4bc6-8351-73f6fd8c214a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip -q install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0e866e88-8f0d-4aaf-a12e-ae7fb91dea3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wikipedia_tool(search_query: str) -> str:\n",
    "    ''' Uses search_query and returns text from wikipedia '''\n",
    "    from langchain.tools import WikipediaQueryRun\n",
    "    from langchain.utilities import WikipediaAPIWrapper\n",
    "\n",
    "    return WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()).run(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9e4cbb92-7e2e-483d-b372-7560c6bd1622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Joe Biden\\nSummary: Joseph Robinette Biden Jr. (  BY-dən; born November 20, 1942) is an America'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool('Joe Biden')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60580ab-b847-422d-8b4c-5ee0015bcc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fa1142de-bb06-4d6c-839b-faa29f6990bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Note: Rate Limit reached\n",
    "def duckduckgo_search_tool(search_query: str) -> str:\n",
    "    ''' Returns the result of duckduckgo search tool with search_query '''\n",
    "    from langchain_community.tools import DuckDuckGoSearchRun\n",
    "    return DuckDuckGoSearchRun().run(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9b3c96-2de4-4e9c-83dd-5862425afd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# duckduckgo_search_tool('What are 5 good restaurants in Singapore?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "113648d9-8b57-4449-8681-dfc86385d6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def python_repl_tool(python_code: str) -> str:\n",
    "    ''' Runs python_code, returns the final result, or any debugging errors '''\n",
    "    from langchain.utilities import PythonREPL\n",
    "    \n",
    "    return PythonREPL().run(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "163cf349-c8b0-444e-a64d-e46f1a72853a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 10:56:00,758 - 140704271009536 - python.py-python:16 - WARNING: Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl_tool('print(3+5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15467ba9-48e8-4c23-943e-dbec1d7d3150",
   "metadata": {},
   "source": [
    "# TaskGen Custom Tools\n",
    "- Some initial tools TaskGen can provide are as follows:\n",
    "    - Code generator: `python_generator_tool`\n",
    "    - Code executor: `python_run_tool`\n",
    "    - Code debugger: `python_debug_tool`\n",
    "    - Code generator, executor and debugger combined: `python_generate_and_run_code_tool`\n",
    "    - Webpage parser: `get_text_from_url_tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "b665c6a5-450b-43a3-a9b8-2167b1aff2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_generator_tool = Function('''Generate code based only on <instruction: str> without additional context.\n",
    "    Ensure that you define all variables and list out all imports.\n",
    "    You can only import the following modules: math, numpy, random, datetime, re, matplotlib, pandas, plotly\n",
    "    Do not define any functions\n",
    "    You are not able to use the Equipped Functions using this tool.\n",
    "    Ensure all required output are in print statements''',\n",
    "                                     output_format = {'Output Code': 'type: code'}, fn_name = 'python_generator_tool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "e5513395-eb20-4b05-9582-2f313fa3900a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Output Code': 'result = 2 + 3\\nprint(result)'}"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_generator_tool('What is 2+3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "ff8a319d-fbb7-4daa-aca4-452078746523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def python_run_tool(code_snippet: str) -> str:\n",
    "    '''Runs code_snippet and outputs the result of all print statements'''\n",
    "    import sys\n",
    "    import io\n",
    "    import math\n",
    "    import numpy\n",
    "    import random\n",
    "    import datetime\n",
    "    import re\n",
    "    import matplotlib\n",
    "    import pandas\n",
    "    import plotly\n",
    "\n",
    "    # Disable file access\n",
    "    def restricted_open(*args, **kwargs):\n",
    "        raise PermissionError(\"File access is restricted\")\n",
    "    \n",
    "    # Capture the output\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "    try:\n",
    "        # Safe environment to execute the user code\n",
    "        allowed_globals = {\n",
    "            '__builtins__': {\n",
    "                'print': print,\n",
    "                'range': range,\n",
    "                'len': len,\n",
    "                'int': int,\n",
    "                'float': float,\n",
    "                'str': str,\n",
    "                'list': list,\n",
    "                'dict': dict,\n",
    "                'set': set,\n",
    "                'tuple': tuple,\n",
    "                'abs': abs,\n",
    "                'min': min,\n",
    "                'max': max,\n",
    "                'sum': sum,\n",
    "                'any': any,\n",
    "                'all': all,\n",
    "                'sorted': sorted,\n",
    "                'zip': zip,\n",
    "                'map': map,\n",
    "                'filter': filter,\n",
    "                '__import__': __import__,\n",
    "                'math': math,  # Allow access to the math module\n",
    "                'datetime': datetime, # Allow access to datetime module\n",
    "                'random': random, # Allow access to random module\n",
    "                'numpy': numpy, # Allow access to numpy module\n",
    "                're': re,\n",
    "                'matplotlib': matplotlib,\n",
    "                'pandas': pandas,\n",
    "                'plotly': plotly,\n",
    "                'open': restricted_open,  # Override open to restrict file access\n",
    "            }\n",
    "        }\n",
    "\n",
    "        safe_locals = {}\n",
    "\n",
    "        exec(code_snippet, allowed_globals, safe_locals)\n",
    "        output = sys.stdout.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        # Restore the original stdout\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "3b24ea1a-8ee8-49b0-8ea3-408807e35bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a great tool to debug and run code!\\nAwesome!\\n'"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_run_tool('print(\"This is a great tool to debug and run code!\")\\nprint(\"Awesome!\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "ad33dc12-e535-4ec3-854b-8a29e7ac1121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_debug_tool = Function('''Debugs Python Code and returns corrected code.\n",
    "Instruction: <instruction: str>\n",
    "Current Code: <python_code: str>\n",
    "Error Message: <error_msg: str>''',\n",
    "                                 output_format = {'Thoughts': 'How to correct code', 'Corrected Code': 'type: code'}, fn_name = 'python_debug_tool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "928c5385-23ce-461d-8435-6ad00f462dba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thoughts': 'The error message indicates that there is an issue with the decimal literal in the code. We need to add a space between the number 3 and the print statement.',\n",
       " 'Corrected Code': 'result = 3\\nprint(result)'}"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_debug_tool('Print result', 'result = 3print(result)', 'invalid decimal literal (<string>, line 1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f55b09-def9-4706-98cb-84a84ba2cf54",
   "metadata": {},
   "source": [
    "## Combining all Python Code tools into one\n",
    "- This is like a rule-based agent, doing the three functions inside it, so that we don't have to keep passing in code as input variable to the functions\n",
    "- This is also a context-based function, taking in agent's overall task and subtasks completed via shared_variables\n",
    "- Do note that you need to pass in the agent as the shared_variables to utilise this function (to be done by default in future versions of TaskGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "04fde2ab-40e9-49e1-a3d2-d36fa899e519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses LLM to generate Code\n",
    "def python_generate_and_run_code_tool(shared_variables, instruction: str) -> str:\n",
    "    ''' Generates and runs code based on instruction. Returns 1) the result of all print statements in code, or error messages, and 2) the code '''\n",
    "    # from termcolor import colored\n",
    "    \n",
    "    # Append context to tool\n",
    "    if shared_variables and 'agent' in shared_variables:\n",
    "        instruction = f\"Context: {shared_variables['agent'].overall_task}\\nPrevious Subtasks: {shared_variables['agent'].subtasks_completed}\\nInstruction: {instruction}\"\n",
    "    # Generate Code\n",
    "    python_code = python_generator_tool(instruction)['Output Code']\n",
    "    # print(colored(f'Generated code: ```{python_code}```', 'magenta'))\n",
    "    \n",
    "    # Run and Debug Code\n",
    "    for _ in range(3):\n",
    "        output = python_run_tool(python_code)\n",
    "\n",
    "        if output[:5] == \"Error\":\n",
    "            debugged_code = python_debug_tool(instruction, python_code, output)\n",
    "            python_code = debugged_code['Corrected Code']\n",
    "            # print(colored(output, 'red'))\n",
    "            # print(colored(f'Debugged code: ```{python_code}```', 'magenta'))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return output, python_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "761e5b7e-cb38-42b4-9b33-49e24f5578ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[3, 7, 11, 13, 17, 19, 23, 29, 31, 37]\\n',\n",
       " 'primes = [3, 7, 11, 13, 17, 19, 23, 29, 31, 37]\\nprint(primes)')"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_code_tool(None, 'Give me first 10 primes, without 2 and 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "41b11393-3a2b-4c75-9bdb-0b8245b0f1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_from_url_tool(url) -> str:\n",
    "    ''' Returns text from a url '''\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from bs4 import BeautifulSoup\n",
    "    from bs4.element import Comment\n",
    "    \n",
    "    # Maximum character length\n",
    "    MAX_LEN = 10000\n",
    "\n",
    "    def tag_visible(element):\n",
    "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "            return False\n",
    "        if isinstance(element, Comment):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def text_from_html(body):\n",
    "        soup = BeautifulSoup(body, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        return text\n",
    "\n",
    "    # Create an instance of Options\n",
    "    options = Options()\n",
    "\n",
    "    # Set the option for headless\n",
    "    options.headless = True\n",
    "\n",
    "    # Set up the WebDriver with the ChromeDriverManager and options\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    driver.implicitly_wait(2)\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    return text_from_html(html)[:MAX_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "12493d87-7e25-4fab-b8d1-8d5799e3616a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Generalist Agent', \n",
    "'''Helps user with tasks. When deterministic output is needed, generate and run code. Do not use LLM for calculations. End task if you need to output to user.''', \n",
    "             summarise_subtasks_count = 10).assign_functions(\n",
    "    [wikipedia_tool, python_code_tool, get_text_from_url_tool])\n",
    "\n",
    "# assign shared variables for agent so code tool can get context of the task\n",
    "agent.shared_variables['agent'] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "8ecd00be-93c2-42e3-9865-5341fd290040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the assigned task, we need to calculate the final number of apples John has after receiving 21 more from Mary and giving 10 to Tim. We can achieve this by performing simple arithmetic operations.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Calculate the final number of apples John has after receiving 21 more from Mary and giving 10 to Tim.\u001b[0m\n",
      "Calling function python_code_tool with parameters {'instruction': 'Calculate the final number of apples John has after receiving 21 more from Mary and giving 10 to Tim.'}\n",
      "> {'output_1': 'John has 16 apples at the end\\n', 'output_2': 'john_apples = 5\\njohn_apples += 21\\njohn_apples -= 10\\nprint(\"John has\", john_apples, \"apples at the end\")'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The current subtask involves determining the final number of apples John has after receiving 21 more from Mary and giving 10 to Tim. The calculation has been completed successfully using Python code.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the assigned task, we need to determine the final number of apples John has at the end. Since we already have the code to perform the calculation, we can simply run the existing code to get the result.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Run the existing Python code to determine the final number of apples John has at the end.\u001b[0m\n",
      "Calling function python_code_tool with parameters {'instruction': 'Run the existing Python code to determine the final number of apples John has at the end.'}\n",
      "> {'output_1': 'John has 16 apples at the end\\n', 'output_2': 'john_apples = 5\\njohn_apples += 21\\njohn_apples -= 10\\nprint(\"John has\", john_apples, \"apples at the end\")'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The subtasks completed involved calculating the final number of apples John has after receiving 21 more from Mary and giving 10 to Tim. The Python code was generated and run to determine that John has 16 apples at the end.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the final number of apples John has at the end has been calculated, the next step is to end the task as there are no further calculations or actions required.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'John has 16 apples at the end\\n',\n",
       "  'output_2': 'john_apples = 5\\njohn_apples += 21\\njohn_apples -= 10\\nprint(\"John has\", john_apples, \"apples at the end\")'},\n",
       " {'output_1': 'John has 16 apples at the end\\n',\n",
       "  'output_2': 'john_apples = 5\\njohn_apples += 21\\njohn_apples -= 10\\nprint(\"John has\", john_apples, \"apples at the end\")'}]"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('John has 5 apples. John received another 21 more from Mary, and gave 10 to Tim. How many apples does John have at the end?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "63f3c0c3-19e5-4465-af6a-aa24e46c4c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John has 16 apples at the end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'John has 16 apples at the end'"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "45745b01-e18a-4863-a356-a25e5ef10d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To plot a graph of y = 2x^2, we need to generate the code for plotting the graph using a Python plotting library like Matplotlib. We can use the python_code_tool function to generate the necessary code for plotting the graph.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Generate and run Python code to plot the graph of y = 2x^2 using Matplotlib.\u001b[0m\n",
      "Calling function python_code_tool with parameters {'instruction': 'Generate and run Python code to plot the graph of y = 2x^2 using Matplotlib.'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> {'output_1': '', 'output_2': 'import matplotlib.pyplot as plt\\nimport numpy as np\\n\\nx = np.linspace(-10, 10, 100)\\ny = 2 * x**2\\n\\nplt.plot(x, y)\\nplt.xlabel(\"x\")\\nplt.ylabel(\"y\")\\nplt.title(\"Graph of y = 2x^2\")\\nplt.grid(True)\\nplt.show()'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The graph of y = 2x^2 has been successfully plotted using Matplotlib in Python.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the graph has been plotted, the next step is to end the task as there are no further subtasks to be completed.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': '',\n",
       "  'output_2': 'import matplotlib.pyplot as plt\\nimport numpy as np\\n\\nx = np.linspace(-10, 10, 100)\\ny = 2 * x**2\\n\\nplt.plot(x, y)\\nplt.xlabel(\"x\")\\nplt.ylabel(\"y\")\\nplt.title(\"Graph of y = 2x^2\")\\nplt.grid(True)\\nplt.show()'}]"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('Plot me a graph of y = 2x^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "6d4cc46c-d2dc-40e0-b124-e5764d6ea058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To find the first 10 prime numbers, we can use a simple algorithm to check for prime numbers. We can start by checking numbers starting from 2 and keep track of the prime numbers found until we have the first 10.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Generate and run code to find the first 10 prime numbers.\u001b[0m\n",
      "Calling function python_code_tool with parameters {'instruction': 'Generate and run code to find the first 10 prime numbers.'}\n",
      "> {'output_1': 'The first 10 prime numbers are: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\\n', 'output_2': 'import math\\n\\nprimes = []\\nnum = 2\\n\\nwhile len(primes) < 10:\\n    is_prime = True\\n    for i in range(2, int(math.sqrt(num)) + 1):\\n        if num % i == 0:\\n            is_prime = False\\n            break\\n    if is_prime:\\n        primes.append(num)\\n    num += 1\\n\\nprint(\"The first 10 prime numbers are:\", primes)'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The first 10 prime numbers have been successfully generated using code.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the first 10 prime numbers have been found, the next step is to end the task as per the user query.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'The first 10 prime numbers are: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\\n',\n",
       "  'output_2': 'import math\\n\\nprimes = []\\nnum = 2\\n\\nwhile len(primes) < 10:\\n    is_prime = True\\n    for i in range(2, int(math.sqrt(num)) + 1):\\n        if num % i == 0:\\n            is_prime = False\\n            break\\n    if is_prime:\\n        primes.append(num)\\n    num += 1\\n\\nprint(\"The first 10 prime numbers are:\", primes)'}]"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('What are the first 10 prime numbers?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "935e82a7-e207-4ff1-9187-d57d57e82806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, we need to find information about Joe Biden and calculate his current age. We can use the Wikipedia tool to gather information about Joe Biden and then calculate his current age based on his birthdate.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Uses \"Joe Biden\" to gather information from Wikipedia\u001b[0m\n",
      "Calling function wikipedia_tool with parameters {'search_query': 'Joe Biden'}\n",
      "> {'output_1': \"Page: Joe Biden\\nSummary: Joseph Robinette Biden Jr. (  BY-dən; born November 20, 1942) is an American politician who is the 46th and current president of the United States since 2021. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009.\\nBorn in Scranton, Pennsylvania, Biden moved with his family to Delaware in 1953. He graduated from the University of Delaware before earning his law degree from Syracuse University. He was elected to the New Castle County Council in 1970 and to the U.S. Senate in 1972. As a senator, Biden drafted and led the effort to pass the Violent Crime Control and Law Enforcement Act and the Violence Against Women Act. He also oversaw six U.S. Supreme Court confirmation hearings, including the contentious hearings for Robert Bork and Clarence Thomas. Biden ran unsuccessfully for the Democratic presidential nomination in 1988 and 2008. In 2008, Obama chose Biden as his running mate, and he was a close counselor to Obama during his two terms as vice president. In the 2020 presidential election, Biden and his running mate, Kamala Harris, defeated incumbents Donald Trump and Mike Pence. He is the oldest president in U.S. history, and the first to have a female vice president.\\nAs president, Biden signed the American Rescue Plan Act in response to the COVID-19 pandemic and subsequent recession. He signed bipartisan bills on infrastructure and manufacturing. He proposed the Build Back Better Act, which failed in Congress, but aspects of which were incorporated into the Inflation Reduction Act that he signed into law in 2022. Biden appointed Ketanji Brown Jackson to the Supreme Court. He worked with congressional Republicans to resolve the 2023 United States debt-ceiling crisis by negotiating a deal to raise the debt ceiling. In foreign policy, Biden restored America's membership in the Paris Agreement. He oversaw the complete withdrawal of U.S. troops from Afghanistan that ended the war in Afghanistan, during which the Afghan government collapsed and the Taliban seized control. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia and authorizing civilian and military aid to Ukraine. During the Israel–Hamas war, Biden condemned the actions of Hamas and other Palestinian militants as terrorism, announced military support for Israel, and ordered the U.S. military to build a port to facilitate the delivery of humanitarian aid to Palestinian civilians in Gaza. In April 2023, Biden announced his candidacy for the Democratic nomination in the 2024 presidential election.\\n\\nPage: Family of Joe Biden\\nSummary: Joe Biden, the 46th and current president of the United States, has family members who are prominent in law, education, activism and politics. Biden's immediate family became the first family of the United States on his inauguration on January 20, 2021. His immediate family circle was also the second family of the United States from 2009 to 2017, when Biden was vice president. Biden's family is mostly descended from the British Isles, with most of their ancestors coming from Ireland and England, and a smaller number descending from the French.\\nOf Joe Biden's sixteen great-great-grandparents, ten were born in Ireland. He is descended from the Blewitts of County Mayo and the Finnegans of County Louth. One of Biden's great-great-great-grandfathers was born in Sussex, England, and emigrated to Maryland in the United States by 1820.\\n\\nPage: Presidency of Joe Biden\\nSummary: Joe Biden's tenure as the 46th president of the United States began with his inauguration on January 20, 2021. Biden, a Democrat from Delaware who previously served as vice president for two terms under President Barack Obama, took office following his victory in the 2020 presidential election over Republican incumbent president Donald Trump. Upon his inauguration, he became the oldes\"}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The information gathered from Wikipedia about Joe Biden includes his birthdate in 1942, making him 80 years old in 2022.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To determine Joe Biden's current age in 2023, we need to calculate the difference between the current year and his birth year. Since we already know his birth year is 1942, we can subtract 1942 from the current year to find his age in 2023.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Calculate Joe Biden's current age in 2023 by subtracting his birth year (1942) from the current year.\u001b[0m\n",
      "Calling function python_code_tool with parameters {'instruction': \"Calculate Joe Biden's current age in 2023 by subtracting his birth year (1942) from the current year.\"}\n",
      "> {'output_1': 'Joe Biden is currently 81 years old in 2023\\n', 'output_2': 'current_year = 2023\\nbirth_year = 1942\\nage = current_year - birth_year\\nprint(\"Joe Biden is currently\", age, \"years old in 2023\")'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The user asked about who Joe Biden is and his current age based on calculation. Information about Joe Biden was gathered from Wikipedia, including his birth year (1942). The calculation was performed to determine his current age in 2023 (81 years old).\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remaining part of the assigned task, we need to provide the user with Joe Biden's current age, which is 81 years old in 2023. This can be achieved by using the calculated age result from the previous step. We can directly output this information to the user to fulfill the task.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': \"Page: Joe Biden\\nSummary: Joseph Robinette Biden Jr. (  BY-dən; born November 20, 1942) is an American politician who is the 46th and current president of the United States since 2021. A member of the Democratic Party, he previously served as the 47th vice president from 2009 to 2017 under President Barack Obama and represented Delaware in the United States Senate from 1973 to 2009.\\nBorn in Scranton, Pennsylvania, Biden moved with his family to Delaware in 1953. He graduated from the University of Delaware before earning his law degree from Syracuse University. He was elected to the New Castle County Council in 1970 and to the U.S. Senate in 1972. As a senator, Biden drafted and led the effort to pass the Violent Crime Control and Law Enforcement Act and the Violence Against Women Act. He also oversaw six U.S. Supreme Court confirmation hearings, including the contentious hearings for Robert Bork and Clarence Thomas. Biden ran unsuccessfully for the Democratic presidential nomination in 1988 and 2008. In 2008, Obama chose Biden as his running mate, and he was a close counselor to Obama during his two terms as vice president. In the 2020 presidential election, Biden and his running mate, Kamala Harris, defeated incumbents Donald Trump and Mike Pence. He is the oldest president in U.S. history, and the first to have a female vice president.\\nAs president, Biden signed the American Rescue Plan Act in response to the COVID-19 pandemic and subsequent recession. He signed bipartisan bills on infrastructure and manufacturing. He proposed the Build Back Better Act, which failed in Congress, but aspects of which were incorporated into the Inflation Reduction Act that he signed into law in 2022. Biden appointed Ketanji Brown Jackson to the Supreme Court. He worked with congressional Republicans to resolve the 2023 United States debt-ceiling crisis by negotiating a deal to raise the debt ceiling. In foreign policy, Biden restored America's membership in the Paris Agreement. He oversaw the complete withdrawal of U.S. troops from Afghanistan that ended the war in Afghanistan, during which the Afghan government collapsed and the Taliban seized control. He responded to the Russian invasion of Ukraine by imposing sanctions on Russia and authorizing civilian and military aid to Ukraine. During the Israel–Hamas war, Biden condemned the actions of Hamas and other Palestinian militants as terrorism, announced military support for Israel, and ordered the U.S. military to build a port to facilitate the delivery of humanitarian aid to Palestinian civilians in Gaza. In April 2023, Biden announced his candidacy for the Democratic nomination in the 2024 presidential election.\\n\\nPage: Family of Joe Biden\\nSummary: Joe Biden, the 46th and current president of the United States, has family members who are prominent in law, education, activism and politics. Biden's immediate family became the first family of the United States on his inauguration on January 20, 2021. His immediate family circle was also the second family of the United States from 2009 to 2017, when Biden was vice president. Biden's family is mostly descended from the British Isles, with most of their ancestors coming from Ireland and England, and a smaller number descending from the French.\\nOf Joe Biden's sixteen great-great-grandparents, ten were born in Ireland. He is descended from the Blewitts of County Mayo and the Finnegans of County Louth. One of Biden's great-great-great-grandfathers was born in Sussex, England, and emigrated to Maryland in the United States by 1820.\\n\\nPage: Presidency of Joe Biden\\nSummary: Joe Biden's tenure as the 46th president of the United States began with his inauguration on January 20, 2021. Biden, a Democrat from Delaware who previously served as vice president for two terms under President Barack Obama, took office following his victory in the 2020 presidential election over Republican incumbent president Donald Trump. Upon his inauguration, he became the oldes\"},\n",
       " {'output_1': 'Joe Biden is currently 81 years old in 2023\\n',\n",
       "  'output_2': 'current_year = 2023\\nbirth_year = 1942\\nage = current_year - birth_year\\nprint(\"Joe Biden is currently\", age, \"years old in 2023\")'}]"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('Who is Joe Biden and how old is he now based on calculation?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "a78e0343-d854-46d2-9bf0-647af8f0ad96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden is an American politician who is the 46th and current president of the United States. He was born on November 20, 1942. Based on calculation, Joe Biden is currently 81 years old in 2023.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Joe Biden is an American politician who is the 46th and current president of the United States. He was born on November 20, 1942. Based on calculation, Joe Biden is currently 81 years old in 2023.'"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "6c860b75-0c0f-48c7-a20a-7a2b1ede56d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To find the number of stars in the TaskGen GitHub repository, we can use the get_text_from_url_tool function to extract the required information from the GitHub page. We will then need to parse the text to find the number of stars.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Use the get_text_from_url_tool function to extract text from the GitHub page of TaskGen (https://github.com/simbianai/taskgen).\u001b[0m\n",
      "Calling function get_text_from_url_tool with parameters {'url': 'https://github.com/simbianai/taskgen'}\n",
      "> {'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\nSign in\\nProduct\\nActions\\nAutomate any workflow\\nPackages\\nHost and manage packages\\nSecurity\\nFind and fix vulnerabilities\\nCodespaces\\nInstant dev environments\\nCopilot\\nWrite better code with AI\\nCode review\\nManage code changes\\nIssues\\nPlan and track work\\nDiscussions\\nCollaborate outside of code\\nExplore\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\nSolutions\\nFor\\nEnterprise\\nTeams\\nStartups\\nEducation\\nBy Solution\\nCI/CD & Automation\\nDevOps\\nDevSecOps\\nResources\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nOpen Source\\nGitHub Sponsors\\nFund open source developers\\nThe ReadME Project\\nGitHub community articles\\nRepositories\\nTopics\\nTrending\\nCollections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel\\nSubmit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\nTo see all available qualifiers, see our documentation.\\nCancel\\nCreate saved search\\nSign in\\nSign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\nsimbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n11\\nStar\\n77\\nTask-based Agentic Framework using StrictJSON as the core\\nLicense\\nMIT license\\n77\\nstars\\n11\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\nmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History99 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0PyGame_Essay_Creator.ipynbPyGame_Essay_Creator.ipynb\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_18May2024.ipynbTaskGen AMA_18May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.3.0\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The text extracted from the GitHub page of TaskGen shows that the repository has 77 stars.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To determine the number of stars in TaskGen GitHub, we can extract the star count from the text. Since we already have the required information, we can directly provide the answer to the user.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'GitHub - simbianai/taskgen: Task-based Agentic Framework using StrictJSON as the core\\nSkip to content\\nNavigation Menu\\nToggle navigation\\nSign in\\nProduct\\nActions\\nAutomate any workflow\\nPackages\\nHost and manage packages\\nSecurity\\nFind and fix vulnerabilities\\nCodespaces\\nInstant dev environments\\nCopilot\\nWrite better code with AI\\nCode review\\nManage code changes\\nIssues\\nPlan and track work\\nDiscussions\\nCollaborate outside of code\\nExplore\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\nSolutions\\nFor\\nEnterprise\\nTeams\\nStartups\\nEducation\\nBy Solution\\nCI/CD & Automation\\nDevOps\\nDevSecOps\\nResources\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nOpen Source\\nGitHub Sponsors\\nFund open source developers\\nThe ReadME Project\\nGitHub community articles\\nRepositories\\nTopics\\nTrending\\nCollections\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel\\nSubmit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName\\nQuery\\nTo see all available qualifiers, see our documentation.\\nCancel\\nCreate saved search\\nSign in\\nSign up\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\nsimbianai\\n/\\ntaskgen\\nPublic\\nNotifications\\nFork\\n11\\nStar\\n77\\nTask-based Agentic Framework using StrictJSON as the core\\nLicense\\nMIT license\\n77\\nstars\\n11\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nCode\\nIssues\\n3\\nPull requests\\n0\\nActions\\nProjects\\n0\\nSecurity\\nInsights\\nAdditional navigation options\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\nsimbianai/taskgen\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\nmainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History99 CommitsPaperPaper\\xa0\\xa0contribcontrib\\xa0\\xa0resourcesresources\\xa0\\xa0taskgentaskgen\\xa0\\xa0.example.env.example.env\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0LICENSELICENSE\\xa0\\xa0PyGame_Essay_Creator.ipynbPyGame_Essay_Creator.ipynb\\xa0\\xa0README.mdREADME.md\\xa0\\xa0TaskGen AMA_18May2024.ipynbTaskGen AMA_18May2024.ipynb\\xa0\\xa0Tutorial 0 - StrictJSON.ipynbTutorial 0 - StrictJSON.ipynb\\xa0\\xa0Tutorial 1 - Agent.ipynbTutorial 1 - Agent.ipynb\\xa0\\xa0Tutorial 2 - Hierarchical Agents.ipynbTutorial 2 - Hierarchical Agents.ipynb\\xa0\\xa0Tutorial 3 - Shared Variables.ipynbTutorial 3 - Shared Variables.ipynb\\xa0\\xa0Tutorial 4 - Memory.ipynbTutorial 4 - Memory.ipynb\\xa0\\xa0Tutorial 5 - Additional Context.ipynbTutorial 5 - Additional Context.ipynb\\xa0\\xa0Tutorial 6 - External Function Interfacing.ipynbTutorial 6 - External Function Interfacing.ipynb\\xa0\\xa0changelog.txtchangelog.txt\\xa0\\xa0myagent.pklmyagent.pkl\\xa0\\xa0pyproject.tomlpyproject.toml\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEMIT licenseTaskGen v2.3.0\\nA Task-based agentic framework building on StrictJSON outputs by LLM agents\\nRelated Repositories: StrictJSON (https://github.com/tanchongmin/strictjson)\\nVideo (Part 1): https://www.youtube.com/watch?v=O_XyTT7QGH4\\nVideo (Part 2): https://www.youtube.com/watch?v=OWk7moRfTPE\\nTaskGen Ask Me Anything: https://www.youtube.com/watch?v=mheIWKugqF4\\nCreator\\'s Preamble\\nHappy to share that the task-based agentic framework I have been working on - TaskGen - is largely complete!\\nNoteable features include:\\nSplitting of Tasks into subtasks for bite-sized solutions for each subtask\\nSingle Agent with LLM Functions\\nSingle Agent with External Functions\\nMeta Agent with Inner Agents as Functions\\nShared Variables for multi-modality support\\nRetrieval Augmented Generation (RAG) over Function space\\nMemory to provide additional task-based prompts for task\\nGlobal Context for configuring your own prompts + add persistent variables\\nI am quite sure that this is the best open-source agentic framework for task-based execution out there!\\nExisting frameworks like AutoGen rely too much on conversational text which is lengthy and not targeted.\\nTaskGen uses StrictJSON (JSON parser with type checking and more!) as the core, and agents are efficient and are able to do Chain of Thought natively using JSON keys and descriptions as a guide.\\nWhat can you do to help:\\nStar the github so more people can use it (It\\'s open source and free to use, even commercially!)\\nContribute your favourite external function integrations so that it can be much more boilerplate for others to use :)\\nContribute template Jupyter Notebooks for your favourite use cases :)\\nI can\\'t wait to see what this new framework can do for you!\\nBenefits of JSON messaging over agentic frameworks using conversational free-text like AutoGen\\nJSON format helps do Chain-of-Thought prompting naturally and is less verbose than free text\\nJSON format allows natural parsing of multiple output fields by agents\\nStrictJSON helps to ensure all output fields are there and of the right format required for downstream processing\\nTutorials and Community Support\\nCreated: 17 Feb 2024 by John Tan Chong Min\\nCollaborators welcome\\nDiscussion Channel (my discord - John\\'s AI Group): https://discord.gg/bzp87AHJy5\\nHow do I use this?\\nDownload package via command line pip install taskgen-ai\\nSet up your OpenAPI API Key\\nImport the required functions from taskgen and use them!\\nDifferences in LLM for Agentic Framework\\nChatGPT (gpt-3.5-turbo) is consistent only if you specify very clearly what you want the Agent to do and give examples of what you want\\ngpt-4-turbo and more advanced models can perform better zero-shot without much examples\\nTaskGen is compatible with ChatGPT and similar models, but for more robust use, consider using gpt-4-turbo and better models\\nAgent Basics - See Tutorial 1\\nCreate an agent by entering your agent\\'s name and description\\nAgents are task-based, so they will help generate subtasks to fulfil your main task\\nAgents are made to be non-verbose, so they will just focus only on task instruction (Much more efficient compared to conversational-based agentic frameworks like AutoGen)\\nExample Agent Creation\\nmy_agent = Agent(\\'Helpful assistant\\', \\'You are a generalist agent\\')\\nExample Agent Task Running - Split the assigned task into subtasks and execute each of them\\n# Run your agent\\noutput = my_agent.run(\\'Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\')\\nSubtask identified: Find 5 words that rhyme with \\'cool\\'\\nGetting LLM to perform the following task: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask identified: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nGetting LLM to perform the following task: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nTask completed successfully!\\nExample Agent Reply to User - Reference the subtasks\\' output to answer the user\\'s query\\noutput = my_agent.reply_user()\\nHere are 5 words that rhyme with \"cool\": pool, rule, fool, tool, school. Here is a 4-sentence poem using these words: \"In the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\"\\nCheck Agent\\'s Status\\nmy_agent.status()\\nAgent Name: Helpful assistant\\nAgent Description: You are a generalist agent\\nAvailable Functions: [\\'use_llm\\', \\'end_task\\']\\nTask: Give me 5 words rhyming with cool, and make a 4-sentence poem using them\\nSubtasks Completed:\\nSubtask: Find 5 words that rhyme with \\'cool\\'\\npool, rule, fool, tool, school\\nSubtask: Compose a 4-sentence poem using the words \\'pool\\', \\'rule\\', \\'fool\\', \\'tool\\', and \\'school\\'\\nIn the school, the golden rule is to never be a fool. Use your mind as a tool, and always follow the pool.\\nIs Task Completed: True\\nFunctions\\nEnhances strict_json() with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\\nUse angle brackets <> to enclose input variable names. First input variable name to appear in fn_description will be first input variable and second to appear will be second input variable. For example, fn_description = \\'Adds up two numbers, <var1> and <var2>\\' will result in a function with first input variable var1 and second input variable var2\\n(Optional) If you would like greater specificity in your function\\'s input, you can describe the variable after the : in the input variable name, e.g. <var1: an integer from 10 to 30>. Here, var1 is the input variable and an integer from 10 to 30 is the description.\\n(Optional) If your description of the variable is one of int, float, str, dict, list, array, Dict[], List[], Array[], Enum[], bool, we will enforce type checking when generating the function inputs in get_next_subtask method of the Agent class. Example: <var1: int> Refer to Tutorial 0, Section 3. Type Forcing Output Variables for details.\\nInputs (primary):\\nfn_description: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\\nNew feature: If external_fn is provided and no fn_description is provided, then we will automatically parse out the fn_description based on docstring of external_fn. Only requirement is that the docstring must contain the names of all compulsory input variables\\noutput_format: Dict. Dictionary containing output variables names and description for each variable.\\nInputs (optional):\\nexamples - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\\nexternal_fn - Python Function. If defined, instead of using LLM to process the function, we will run the external function.\\nIf there are multiple outputs of this function, we will map it to the keys of output_format in a one-to-one fashion'}]"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run('What are the number of stars in TaskGen GitHub? (https://github.com/simbianai/taskgen)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "d40a5ef6-9ba7-44ff-981b-dae6a5389ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of stars in TaskGen GitHub is 77.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The number of stars in TaskGen GitHub is 77.'"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reply_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda84665-304f-4e22-94d9-dab271d909a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LlamaIndex Function Interface with TaskGen\n",
    "- If User defines a function in LlamaIndex, simply just add <fn_name>.fn to TaskGen Agent\n",
    "- TODO: Add structure for other kinds of functions in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "cd7cad1e-abe9-4f13-9478-ccabd02338e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Usfeful for getting the weather for a given location.\"\"\"\n",
    "    return 'Sunny'\n",
    "    ...\n",
    "\n",
    "tool = FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    # async_fn=aget_weather,  # optional!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a5dbfa06-9849-4864-b775-094bcf98e401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Weather Agent', 'Returns the Weather').assign_functions(tool.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "366387df-b36c-44a1-b45a-fa6cd2b58fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Name: use_llm\\nDescription: For general tasks. Used only when no other function can do the task\\nInput: []\\nOutput: {'Output': 'Output of LLM'}\\n\",\n",
       " 'Name: end_task\\nDescription: Use only after task is completed\\nInput: []\\nOutput: {}\\n',\n",
       " \"Name: get_weather\\nDescription: Usfeful for getting the weather for a given <location: str>.\\nInput: ['location']\\nOutput: {'output_1': 'str'}\\n\"]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.list_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "29544561-a87c-4190-ad87-9d9f4c3cb235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks completed yet\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since no subtasks have been completed yet, the first step would be to use the get_weather function to retrieve the weather information for the specified location, which in this case is Miami.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Retrieve the weather information for Miami\u001b[0m\n",
      "Calling function get_weather with parameters {'location': 'Miami'}\n",
      "> {'output_1': 'Sunny'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The weather information for Miami has been retrieved successfully (Sunny).\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the weather information for Miami has been obtained, the next step is to end the task.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'Sunny'}]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What is the weather in Miami?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
