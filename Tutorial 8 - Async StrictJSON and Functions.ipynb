{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec216685-5ec3-497c-9ef8-e1758ca30423",
   "metadata": {},
   "source": [
    "# Tutorial 8: Async StrictJSON\n",
    "\n",
    "- This is an async version of Tutorial 0: StrictJSON using fully async functions and classes\n",
    "\n",
    "- We use `AsyncFunction` and `strict_json_async`\n",
    "    - These are the async equivalents of `Function` and `strict_json`\n",
    "    \n",
    "- Using Async can help do parallel processes simulataneously, resulting in a much faster workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692060b-12c7-4224-8faf-c104892648e3",
   "metadata": {},
   "source": [
    "# Setup Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f7d98-ebf0-45ad-ae8c-86f01fc641de",
   "metadata": {},
   "source": [
    "## Step 1: Install TaskGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf134f7-108e-48f3-b2e7-88c3b518ae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install taskgen-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc79be-6723-4dba-a555-4782cdb651b1",
   "metadata": {},
   "source": [
    "## Step 2: Set up OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2280c7-1d2c-4639-b4be-032313ec1b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Python way to set up OpenAI API Keys\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR_API_KEY_HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2145d5c-a309-4fdc-be45-42144d7a5e4c",
   "metadata": {},
   "source": [
    "## Step 3: Import required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef256af-e9d4-4f59-af18-0570b0b49bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89870084-63d6-4227-bae7-30578a3f005f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Basic Generation\n",
    "\n",
    "- **system_prompt**: Write in whatever you want GPT to become. \"You are a \\<purpose in life\\>\"\n",
    "- **user_prompt**: The user input. Later, when we use it as a function, this is the function input\n",
    "- **output_format**: JSON of output variables in a dictionary, with the key as the output key, and the value as the output description\n",
    "    - The output keys will be preserved exactly, while GPT will generate content to match the description of the value as best as possible\n",
    "\n",
    "#### Example Usage\n",
    "```python\n",
    "res = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment',\n",
    "                                    'Adjectives': 'Array of adjectives',\n",
    "                                    'Words': 'Number of words'})\n",
    "                                    \n",
    "print(res)\n",
    "```\n",
    "\n",
    "#### Example Output\n",
    "```{'Sentiment': 'Positive', 'Adjectives': ['beautiful', 'sunny'], 'Words': 7}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9099840-700d-403a-bc3c-28843d0295c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'Positive', 'Adjectives': ['beautiful', 'sunny'], 'Words': 7}\n"
     ]
    }
   ],
   "source": [
    "### Async\n",
    "res = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment',\n",
    "                                    'Adjectives': 'Array of adjectives',\n",
    "                                    'Words': 'Number of words'})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2f8c2-8bcd-40ce-84c8-3e2e18f644d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Easy to split into corresponding elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2ee9a7-9583-4081-b66e-aa8f790a37b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive', ['beautiful', 'sunny'], 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['Sentiment'], res['Adjectives'], res['Words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a88380-bc9b-4b1f-84ec-906906313369",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Type forcing output variables\n",
    "- Generally, ```strict_json_async``` will infer the data type automatically for you for the output fields\n",
    "- However, if you would like very specific data types, you can do data forcing using ```type: <data_type>``` at the last part of the output field description\n",
    "- ```<data_type>``` must be of the form `int`, `float`, `str`, `dict`, `list`, `array`, `code`, `Dict[]`, `List[]`, `Array[]`, `Enum[]`, `bool` for type checking to work\n",
    "- `code` removes all unicode escape characters that might interfere with normal code running\n",
    "- The `Enum` and `List` are not case sensitive, so `enum` and `list` works just as well\n",
    "- For `Enum[list_of_category_names]`, it is best to give an \"Other\" category in case the LLM fails to classify correctly with the other options.\n",
    "- If `list` or `List[]` is not formatted correctly in LLM's output, we will correct it by asking the LLM to list out the elements line by line\n",
    "- For `dict`,  we can further check whether keys are present using `Dict[list_of_key_names]`\n",
    "- Other types will first be forced by rule-based conversion, any further errors will be fed into LLM's error feedback mechanism\n",
    "- If `<data_type>` is not the specified data types, it can still be useful to shape the output for the LLM. However, no type checking will be done.\n",
    "- Note: GPT understands the word `Array` better than `List` since `Array` is the official JSON object type, so backend, any type with the word `List` will be converted to `Array`. It is also recommended that you mention `Array` instead of `List` in your `output_format` free text description\n",
    "\n",
    "### LLM-based checks\n",
    "- If you would like the LLM to ensure that the type is being met, use `type: ensure <requirement>`\n",
    "- This will run a LLM to check if the requirement is met. If requirement is not met, the LLM will generate what needs to be done to meet the requirement, which will be fed into the error-correcting loop of `strict_json_async`\n",
    "\n",
    "#### Example Usage 1\n",
    "```python\n",
    "res = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment, type: Enum[\"Pos\", \"Neg\", \"Other\"]',\n",
    "                                    'Adjectives': 'Array of adjectives, type: List[str]',\n",
    "                                    'Words': 'Number of words, type: int',\n",
    "                                    'In English': 'Whether sentence is in English, type: bool'})\n",
    "                                    \n",
    "print(res)\n",
    "```\n",
    "\n",
    "#### Example Output 1\n",
    "```{'Sentiment': 'Pos', 'Adjectives': ['beautiful', 'sunny'], 'Words': 7, 'In English': True}```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcac6c2-b3a1-4171-8931-dc6f6ff763e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': 'Pos',\n",
       " 'Adjectives': ['beautiful', 'sunny'],\n",
       " 'Words': 7,\n",
       " 'In English': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Async\n",
    "res = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment, type: Enum[\"Pos\", \"Neg\", \"Other\"]',\n",
    "                                    'Adjectives': 'Array of Adjectives, type: List[str]',\n",
    "                                    'Words': 'Number of words, type: int',\n",
    "                                    'In English': 'Whether sentence is in English, type: bool'})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f0a58-f8ad-4adc-aeea-45eda85e43f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Functions\n",
    "- Enhances ```strict_json_async()``` with a function-like interface for repeated use of modular LLM-based functions (or wraps external functions)\n",
    "- Use angle brackets <> to enclose input variable names. First input variable name to appear in `fn_description` will be first input variable and second to appear will be second input variable. For example, `fn_description = 'Adds up two numbers, <var1> and <var2>'` will result in a function with first input variable `var1` and second input variable `var2`\n",
    "- (Optional) If you would like greater specificity in your function's input, you can describe the variable after the : in the input variable name, e.g. `<var1: an integer from 10 to 30>`. Here, `var1` is the input variable and `an integer from 10 to 30` is the description.\n",
    "- (Optional) If your description of the variable is one of `int`, `float`, `str`, `dict`, `list`, `array`, `Dict[]`, `List[]`, `Array[]`, `Enum[]`, `bool`, we will enforce type checking when generating the function inputs in `get_next_subtask` method of the `Agent` class. Example: `<var1: int>`. Refer to Section 3. Type Forcing Output Variables for details.\n",
    "- Inputs (primary):\n",
    "    - **fn_description**: String. Function description to describe process of transforming input variables to output variables. Variables must be enclosed in <> and listed in order of appearance in function input.\n",
    "        - New feature: If `external_fn` is provided and no `fn_description` is provided, then we will automatically parse out the fn_description based on docstring of `external_fn`. Only requirement is that the docstring must contain the names of all compulsory input variables\n",
    "    - **output_format**: Dict. Dictionary containing output variables names and description for each variable.\n",
    "    \n",
    "- Inputs (optional):\n",
    "    - **examples** - Dict or List[Dict]. Examples in Dictionary form with the input and output variables (list if more than one)\n",
    "    - **external_fn** - Python Function. If defined, instead of using LLM to process the function, we will run the external function. \n",
    "        If there are multiple outputs of this function, we will map it to the keys of `output_format` in a one-to-one fashion\n",
    "    - **fn_name** - String. If provided, this will be the name of the function. Otherwise, if `external_fn` is provided, it will be the name of `external_fn`. Otherwise, we will use LLM to generate a function name from the `fn_description`\n",
    "    - **kwargs** - Dict. Additional arguments you would like to pass on to the strict_json function\n",
    "        \n",
    "- Outputs:\n",
    "    JSON of output variables in a dictionary (similar to ```strict_json_async```)\n",
    "    \n",
    "#### Example Usage 1 (Description only)\n",
    "```python\n",
    "# basic configuration with variable names (in order of appearance in fn_description)\n",
    "fn = AsyncFunction(fn_description = 'Output a sentence with <obj> and <entity> in the style of <emotion>', \n",
    "                     output_format = {'output': 'sentence'})\n",
    "# If fn_name is missing from definition and you want llm to autogenerate it then call async_init on that function\n",
    "await fn.async_init()\n",
    "\n",
    "# Use the function\n",
    "await fn('ball', 'dog', 'happy') #obj, entity, emotion\n",
    "```\n",
    "\n",
    "#### Example Output 1\n",
    "```{'output': 'The happy dog chased the ball.'}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a237cb26-2655-4d44-80cb-89454562a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'The dog happily played with the ball.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If fn_name is missing from definition and you want llm to autogenerate it then call async_init on that function\n",
    "\n",
    "fn =  AsyncFunction(fn_description = 'Output a sentence with <obj> and <entity> in the style of <emotion>', \n",
    "                     output_format = {'output': 'sentence'})\n",
    "await fn.async_init()\n",
    "res= await fn('ball', 'dog', 'happy') #obj, entity, emotion\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f017fc5-c20d-4a06-a2bd-12f4dd360f6d",
   "metadata": {},
   "source": [
    "## External Function Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74cc0840-588c-4f65-b312-7777a8c8deff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': 4, 'output2': 5, 'output3': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def consecutive_sum(x):\n",
    "    return x, x+1, x+2\n",
    "\n",
    "# Async\n",
    "fn_async = AsyncFunction(fn_description = 'Given input <x: int>, output x, x+1, x+8', \n",
    "            output_format = {'output1': 'x', 'output2': 'x+8', 'output3': 'x+2'},\n",
    "            external_fn = consecutive_sum)\n",
    "\n",
    "await fn_async.async_init()\n",
    "\n",
    "# Use the function\n",
    "res =await fn_async(4) #x\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7be1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': 4, 'output2': 5, 'output3': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Async External function\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Async external function\n",
    "async def consecutive_sum_async(x):\n",
    "    await asyncio.sleep(1)  # simulate some async operation like I/O\n",
    "    return x, x+1, x+2\n",
    "\n",
    "# Async\n",
    "# an external function with multiple output variables\n",
    "fn_async = AsyncFunction(fn_description = 'Given input <x: int>, output x, x+1, x+8', \n",
    "            output_format = {'output1': 'x', 'output2': 'x+8', 'output3': 'x+2'},\n",
    "            external_fn = consecutive_sum_async)\n",
    "\n",
    "# Use the function\n",
    "res =await fn_async(4) #x\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a00d9-0c77-476d-9e49-d872465fa681",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example inferring of fn_description from docstring and type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba9e0417-a265-4a71-9e50-fb0afe6d2da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Adds <num1: int> to <num_list: list>\n",
      "Input: ['num1', 'num_list']\n",
      "Output: {'num_list': 'Array of numbers'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_list': [2, 4, 5, 3]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docstring must provide all input variables\n",
    "# We will ignore shared_variables, *args and **kwargs\n",
    "def add_number_to_list(num1: int, num_list: list, *args, **kwargs):\n",
    "    '''Adds num1 to num_list'''\n",
    "    num_list.append(num1)\n",
    "    return num_list\n",
    "\n",
    "# Async\n",
    "fn_async = AsyncFunction(external_fn = add_number_to_list, \n",
    "    output_format = {'num_list': 'Array of numbers'})\n",
    "\n",
    "\n",
    "print(str(fn_async))\n",
    "\n",
    "# Use the function\n",
    "res_async = await fn_async(3, [2, 4, 5])\n",
    "res_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb58c9f-114f-4c4e-bb81-2c2ce7be6f63",
   "metadata": {},
   "source": [
    "# 5. Integrating with your own LLM\n",
    "- StrictJSON has native support for OpenAI LLMs (you can put the LLM API parameters inside `strict_json_async` or `AsyncFunction` directly)\n",
    "- If your LLM is not from OpenAI, it is really easy to integrate with your own Custom LLM\n",
    "- Simply pass your custom LLM function inside the `llm` parameter of `strict_json_async` or `AsyncFunction`\n",
    "    - Inputs:\n",
    "        - system_prompt: String. Write in whatever you want the LLM to become. e.g. \"You are a \\<purpose in life\\>\"\n",
    "        - user_prompt: String. The user input. Later, when we use it as a function, this is the function input\n",
    "    - Output:\n",
    "        - res: String. The response of the LLM call\n",
    "\n",
    "#### Example Custom LLM\n",
    "```python\n",
    "\n",
    "async def custom_llm_async(system_prompt: str, user_prompt: str):\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = AsyncOpenAI()\n",
    "    response = await client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "```\n",
    "\n",
    "#### Example Usage with `strict_json_async`\n",
    "```python\n",
    "\n",
    "res_ = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment',\n",
    "                                    'Adjectives': 'Array of adjectives',\n",
    "                                    'Words': 'Number of words'},\n",
    "                                     llm = custom_llm_async) # set this to your own LLM                                     \n",
    "\n",
    "print(res)\n",
    "```\n",
    "\n",
    "#### Example Output\n",
    "```{'Sentiment': 'Positive', 'Adjectives': ['beautiful', 'sunny'], 'Words': 7}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87737d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "async def custom_llm_async(system_prompt: str, user_prompt: str):\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = AsyncOpenAI()\n",
    "    response = await client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6801e1-72f4-4fcf-813d-48314fbfe8ad",
   "metadata": {},
   "source": [
    "### Executing Custom LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef9b74a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'Positive', 'Adjectives': ['beautiful', 'sunny'], 'Words': 7}\n"
     ]
    }
   ],
   "source": [
    "# Async\n",
    "llm = custom_llm_async\n",
    "\n",
    "res = await strict_json_async(system_prompt = 'You are a classifier',\n",
    "                    user_prompt = 'It is a beautiful and sunny day',\n",
    "                    output_format = {'Sentiment': 'Type of Sentiment',\n",
    "                                    'Adjectives': 'Array of adjectives',\n",
    "                                    'Words': 'Number of words'},\n",
    "                                     llm = llm) # set this to your own LLM\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718432e-febe-48e7-bcd0-d0834132fe61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
